{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåû CLASIFICACI√ìN ML: PREDICCI√ìN DE CAPACIDAD DE PAGO PARA PANELES SOLARES\n",
    "\n",
    "**Objetivo:** Desarrollar un modelo de Machine Learning que prediga si un cliente puede pagar por paneles solares.\n",
    "\n",
    "**Variable objetivo:** `Puede_Pagar_Solar` (S√≠/No)\n",
    "\n",
    "**Dataset:** Paneles_solares_con_outliers.xlsx - Hoja: Datos Limpios\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö 1. IMPORTAR LIBRER√çAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulaci√≥n de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning - Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Machine Learning - Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Machine Learning - M√©tricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# Guardar modelos\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuraci√≥n\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Estilo de gr√°ficos\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")\n",
    "print(f\"Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 2. CARGA Y EXPLORACI√ìN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "df = pd.read_excel('Paneles_solares_con_outliers.xlsx', sheet_name='Datos Limpios')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INFORMACI√ìN DEL DATASET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDimensiones: {df.shape}\")\n",
    "print(f\"Registros: {len(df)}\")\n",
    "print(f\"Variables: {df.shape[1]}\")\n",
    "print(f\"\\nColumnas:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nTipos de datos:\\n{df.dtypes}\")\n",
    "print(f\"\\nValores nulos:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRIMERAS 10 FILAS\")\n",
    "print(\"=\"*70)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de la variable objetivo\n",
    "print(\"=\"*70)\n",
    "print(\"AN√ÅLISIS DE VARIABLE OBJETIVO: Puede_Pagar_Solar\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Distribuci√≥n\n",
    "print(\"\\nDistribuci√≥n de clases:\")\n",
    "print(df['Puede_Pagar_Solar'].value_counts())\n",
    "\n",
    "print(\"\\nPorcentaje:\")\n",
    "print(df['Puede_Pagar_Solar'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualizaci√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gr√°fico de barras\n",
    "df['Puede_Pagar_Solar'].value_counts().plot(kind='bar', ax=axes[0], color=['#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Distribuci√≥n de Clases', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Puede Pagar Solar', fontsize=12)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=12)\n",
    "axes[0].set_xticklabels(['No', 'S√≠'], rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Gr√°fico de pie\n",
    "colors = ['#e74c3c', '#2ecc71']\n",
    "df['Puede_Pagar_Solar'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
    "                                              colors=colors, startangle=90)\n",
    "axes[1].set_title('Proporci√≥n de Clases', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcular desbalance\n",
    "class_counts = df['Puede_Pagar_Solar'].value_counts()\n",
    "imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "print(f\"\\nRatio de desbalance: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "if imbalance_ratio > 1.5:\n",
    "    print(\"‚ö†Ô∏è ADVERTENCIA: Dataset desbalanceado. Considerar t√©cnicas de balanceo.\")\n",
    "else:\n",
    "    print(\"‚úì Dataset balanceado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "print(\"=\"*70)\n",
    "print(\"ESTAD√çSTICAS DESCRIPTIVAS - VARIABLES NUM√âRICAS\")\n",
    "print(\"=\"*70)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de variables categ√≥ricas\n",
    "print(\"=\"*70)\n",
    "print(\"AN√ÅLISIS DE VARIABLES CATEG√ìRICAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "categorical_cols = ['Sector', 'Ciudad', 'Validar']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts())\n",
    "    print(f\"Total de categor√≠as √∫nicas: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 3. AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de variables num√©ricas\n",
    "numeric_cols = ['Consumo_kWh_Mensual', 'Estrato', 'Area_m2', 'Factura_Mensual_COP']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    axes[i].hist(df[col].dropna(), bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(f'Distribuci√≥n de {col}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(col, fontsize=10)\n",
    "    axes[i].set_ylabel('Frecuencia', fontsize=10)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots por clase objetivo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    df.boxplot(column=col, by='Puede_Pagar_Solar', ax=axes[i])\n",
    "    axes[i].set_title(f'{col} por Capacidad de Pago', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('Puede Pagar Solar', fontsize=10)\n",
    "    axes[i].set_ylabel(col, fontsize=10)\n",
    "    axes[i].get_figure().suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlaci√≥n - Variables Num√©ricas', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelaciones m√°s fuertes:\")\n",
    "corr_pairs = correlation_matrix.unstack()\n",
    "corr_pairs = corr_pairs[corr_pairs != 1].sort_values(ascending=False)\n",
    "print(corr_pairs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 4. PREPROCESAMIENTO DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia para preprocesamiento\n",
    "df_model = df.copy()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPROCESAMIENTO DE DATOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Eliminar columnas no necesarias\n",
    "columns_to_drop = ['ID_Cliente', 'Validar']\n",
    "df_model = df_model.drop(columns=columns_to_drop)\n",
    "print(f\"\\n‚úì Columnas eliminadas: {columns_to_drop}\")\n",
    "\n",
    "# 2. Convertir variable objetivo a binaria (0/1)\n",
    "df_model['Puede_Pagar_Solar'] = df_model['Puede_Pagar_Solar'].map({'No': 0, 'S√≠': 1})\n",
    "print(\"\\n‚úì Variable objetivo convertida a binaria (No=0, S√≠=1)\")\n",
    "\n",
    "# 3. Codificar variables categ√≥ricas\n",
    "categorical_features = ['Sector', 'Ciudad']\n",
    "\n",
    "print(\"\\n‚úì Codificando variables categ√≥ricas:\")\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col] = le.fit_transform(df_model[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"   - {col}: {len(le.classes_)} categor√≠as\")\n",
    "\n",
    "# 4. Imputar valores nulos\n",
    "print(\"\\n‚úì Imputando valores nulos:\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "numeric_features = ['Consumo_kWh_Mensual', 'Area_m2', 'Factura_Mensual_COP']\n",
    "\n",
    "for col in numeric_features:\n",
    "    if df_model[col].isnull().sum() > 0:\n",
    "        df_model[col] = imputer.fit_transform(df_model[[col]])\n",
    "        print(f\"   - {col}: {df_model[col].isnull().sum()} nulos imputados\")\n",
    "\n",
    "print(f\"\\n‚úì Valores nulos restantes: {df_model.isnull().sum().sum()}\")\n",
    "print(f\"\\n‚úì Dataset preprocesado: {df_model.shape}\")\n",
    "\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features y target\n",
    "X = df_model.drop('Puede_Pagar_Solar', axis=1)\n",
    "y = df_model['Puede_Pagar_Solar']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SEPARACI√ìN DE FEATURES Y TARGET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFeatures (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nVariables predictoras:\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(f\"\\nDistribuci√≥n de clases en y:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ 5. DIVISI√ìN DE DATOS Y ESCALADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n train/test con estratificaci√≥n\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DIVISI√ìN DE DATOS (80% TRAIN / 20% TEST)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTrain: {X_train.shape[0]} muestras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test:  {X_test.shape[0]} muestras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nDistribuci√≥n de clases en Train:\")\n",
    "print(y_train.value_counts())\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nDistribuci√≥n de clases en Test:\")\n",
    "print(y_test.value_counts())\n",
    "print(y_test.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ESCALADO DE FEATURES (StandardScaler)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚úì Features escaladas\")\n",
    "print(f\"\\nMedia de X_train_scaled: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Desviaci√≥n est√°ndar de X_train_scaled: {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 6. ENTRENAMIENTO DE MODELOS DE CLASIFICACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos a entrenar\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"ENTRENANDO {len(models)} MODELOS DE CLASIFICACI√ìN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Diccionario para almacenar resultados\n",
    "results = {}\n",
    "\n",
    "# Entrenar cada modelo\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Modelo: {name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Entrenar\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Probabilidades (si est√° disponible)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = None\n",
    "    \n",
    "    # M√©tricas en Train\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    # M√©tricas en Test\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision = precision_score(y_test, y_pred_test)\n",
    "    recall = recall_score(y_test, y_pred_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)\n",
    "    \n",
    "    # AUC-ROC\n",
    "    if y_pred_proba is not None:\n",
    "        auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        auc_roc = None\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc_roc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'y_pred': y_pred_test,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    # Imprimir resultados\n",
    "    print(f\"\\nAccuracy (Train): {train_accuracy:.4f}\")\n",
    "    print(f\"Accuracy (Test):  {test_accuracy:.4f}\")\n",
    "    print(f\"Precision:        {precision:.4f}\")\n",
    "    print(f\"Recall:           {recall:.4f}\")\n",
    "    print(f\"F1-Score:         {f1:.4f}\")\n",
    "    if auc_roc:\n",
    "        print(f\"AUC-ROC:          {auc_roc:.4f}\")\n",
    "    print(f\"CV Accuracy:      {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì ENTRENAMIENTO COMPLETADO\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 7. COMPARACI√ìN DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de comparaci√≥n\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modelo': list(results.keys()),\n",
    "    'Accuracy (Train)': [r['train_accuracy'] for r in results.values()],\n",
    "    'Accuracy (Test)': [r['test_accuracy'] for r in results.values()],\n",
    "    'Precision': [r['precision'] for r in results.values()],\n",
    "    'Recall': [r['recall'] for r in results.values()],\n",
    "    'F1-Score': [r['f1_score'] for r in results.values()],\n",
    "    'AUC-ROC': [r['auc_roc'] if r['auc_roc'] else 0 for r in results.values()],\n",
    "    'CV Mean': [r['cv_mean'] for r in results.values()],\n",
    "    'CV Std': [r['cv_std'] for r in results.values()]\n",
    "})\n",
    "\n",
    "# Ordenar por F1-Score\n",
    "comparison_df = comparison_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPARACI√ìN DE MODELOS\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model_name = comparison_df.iloc[0]['Modelo']\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"   F1-Score: {comparison_df.iloc[0]['F1-Score']:.4f}\")\n",
    "print(f\"   AUC-ROC:  {comparison_df.iloc[0]['AUC-ROC']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de comparaci√≥n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Gr√°fico 1: Accuracy comparaci√≥n\n",
    "comparison_df.plot(x='Modelo', y=['Accuracy (Train)', 'Accuracy (Test)'], \n",
    "                   kind='bar', ax=axes[0, 0], color=['#3498db', '#e74c3c'])\n",
    "axes[0, 0].set_title('Accuracy: Train vs Test', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0, 0].set_xlabel('')\n",
    "axes[0, 0].legend(['Train', 'Test'])\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "axes[0, 0].set_xticklabels(comparison_df['Modelo'], rotation=45, ha='right')\n",
    "\n",
    "# Gr√°fico 2: M√©tricas de clasificaci√≥n\n",
    "comparison_df.plot(x='Modelo', y=['Precision', 'Recall', 'F1-Score'], \n",
    "                   kind='bar', ax=axes[0, 1], color=['#2ecc71', '#f39c12', '#9b59b6'])\n",
    "axes[0, 1].set_title('M√©tricas de Clasificaci√≥n', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Score', fontsize=12)\n",
    "axes[0, 1].set_xlabel('')\n",
    "axes[0, 1].legend(['Precision', 'Recall', 'F1-Score'])\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "axes[0, 1].set_xticklabels(comparison_df['Modelo'], rotation=45, ha='right')\n",
    "\n",
    "# Gr√°fico 3: AUC-ROC\n",
    "comparison_df_with_auc = comparison_df[comparison_df['AUC-ROC'] > 0]\n",
    "comparison_df_with_auc.plot(x='Modelo', y='AUC-ROC', kind='barh', \n",
    "                             ax=axes[1, 0], color='#1abc9c', legend=False)\n",
    "axes[1, 0].set_title('AUC-ROC por Modelo', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('AUC-ROC', fontsize=12)\n",
    "axes[1, 0].set_ylabel('')\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Gr√°fico 4: Cross-Validation con error bars\n",
    "x_pos = np.arange(len(comparison_df))\n",
    "axes[1, 1].bar(x_pos, comparison_df['CV Mean'], yerr=comparison_df['CV Std'],\n",
    "               color='#34495e', alpha=0.7, capsize=5)\n",
    "axes[1, 1].set_title('Cross-Validation Accuracy (5-Fold)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1, 1].set_xlabel('Modelo', fontsize=12)\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels(comparison_df['Modelo'], rotation=45, ha='right')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 8. AN√ÅLISIS DETALLADO DEL MEJOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener mejor modelo\n",
    "best_model = results[best_model_name]['model']\n",
    "y_pred_best = results[best_model_name]['y_pred']\n",
    "y_pred_proba_best = results[best_model_name]['y_pred_proba']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"AN√ÅLISIS DETALLADO: {best_model_name}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Reporte de clasificaci√≥n\n",
    "print(\"\\nREPORTE DE CLASIFICACI√ìN:\\n\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=['No Puede Pagar', 'S√≠ Puede Pagar']))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "print(\"\\nMATRIZ DE CONFUSI√ìN:\\n\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de matriz de confusi√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matriz de confusi√≥n - Valores absolutos\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['No', 'S√≠'], yticklabels=['No', 'S√≠'])\n",
    "axes[0].set_title(f'Matriz de Confusi√≥n - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Valor Real', fontsize=12)\n",
    "axes[0].set_xlabel('Predicci√≥n', fontsize=12)\n",
    "\n",
    "# Matriz de confusi√≥n - Normalizada\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=['No', 'S√≠'], yticklabels=['No', 'S√≠'])\n",
    "axes[1].set_title(f'Matriz de Confusi√≥n Normalizada - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Valor Real', fontsize=12)\n",
    "axes[1].set_xlabel('Predicci√≥n', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretaci√≥n de la matriz\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nINTERPRETACI√ìN DE LA MATRIZ:\")\n",
    "print(f\"  Verdaderos Negativos (TN): {tn} - Correctamente clasificados como NO\")\n",
    "print(f\"  Falsos Positivos (FP):     {fp} - Incorrectamente clasificados como S√ç\")\n",
    "print(f\"  Falsos Negativos (FN):     {fn} - Incorrectamente clasificados como NO\")\n",
    "print(f\"  Verdaderos Positivos (TP): {tp} - Correctamente clasificados como S√ç\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas ROC y Precision-Recall\n",
    "if y_pred_proba_best is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Curva ROC\n",
    "    fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba_best)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "    axes[0].set_xlim([0.0, 1.0])\n",
    "    axes[0].set_ylim([0.0, 1.05])\n",
    "    axes[0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "    axes[0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "    axes[0].set_title(f'Curva ROC - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(loc=\"lower right\")\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Curva Precision-Recall\n",
    "    precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test, y_pred_proba_best)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    \n",
    "    axes[1].plot(recall_curve, precision_curve, color='green', lw=2, \n",
    "                 label=f'PR curve (AUC = {pr_auc:.4f})')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel('Recall', fontsize=12)\n",
    "    axes[1].set_ylabel('Precision', fontsize=12)\n",
    "    axes[1].set_title(f'Curva Precision-Recall - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(loc=\"lower left\")\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úì AUC-ROC: {roc_auc:.4f}\")\n",
    "    print(f\"‚úì AUC-PR:  {pr_auc:.4f}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Este modelo no soporta predict_proba, no se pueden generar curvas ROC/PR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 9. GUARDAR MODELO Y ARTEFACTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar mejor modelo\n",
    "print(\"=\"*70)\n",
    "print(\"GUARDANDO MODELO Y ARTEFACTOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Guardar modelo\n",
    "joblib.dump(best_model, 'best_model_pago_solar.pkl')\n",
    "print(\"\\n‚úì Modelo guardado: best_model_pago_solar.pkl\")\n",
    "\n",
    "# 2. Guardar scaler\n",
    "joblib.dump(scaler, 'scaler_pago_solar.pkl')\n",
    "print(\"‚úì Scaler guardado: scaler_pago_solar.pkl\")\n",
    "\n",
    "# 3. Guardar label encoders\n",
    "joblib.dump(label_encoders, 'label_encoders_pago_solar.pkl')\n",
    "print(\"‚úì Label encoders guardados: label_encoders_pago_solar.pkl\")\n",
    "\n",
    "# 4. Guardar informaci√≥n del modelo\n",
    "model_info = {\n",
    "    'modelo': best_model_name,\n",
    "    'fecha_entrenamiento': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'metricas': {\n",
    "        'accuracy_train': float(results[best_model_name]['train_accuracy']),\n",
    "        'accuracy_test': float(results[best_model_name]['test_accuracy']),\n",
    "        'precision': float(results[best_model_name]['precision']),\n",
    "        'recall': float(results[best_model_name]['recall']),\n",
    "        'f1_score': float(results[best_model_name]['f1_score']),\n",
    "        'auc_roc': float(results[best_model_name]['auc_roc']) if results[best_model_name]['auc_roc'] else None,\n",
    "        'cv_mean': float(results[best_model_name]['cv_mean']),\n",
    "        'cv_std': float(results[best_model_name]['cv_std'])\n",
    "    },\n",
    "    'clases': ['No', 'S√≠'],\n",
    "    'variables_predictoras': list(X.columns),\n",
    "    'total_registros': len(df_model),\n",
    "    'train_size': len(X_train),\n",
    "    'test_size': len(X_test)\n",
    "}\n",
    "\n",
    "with open('model_info_pago_solar.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_info, f, indent=2, ensure_ascii=False)\n",
    "print(\"‚úì Informaci√≥n del modelo guardada: model_info_pago_solar.json\")\n",
    "\n",
    "# 5. Guardar comparaci√≥n de modelos\n",
    "comparison_df.to_excel('comparacion_modelos_pago_solar.xlsx', index=False)\n",
    "print(\"‚úì Comparaci√≥n de modelos guardada: comparacion_modelos_pago_solar.xlsx\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì TODOS LOS ARTEFACTOS GUARDADOS CORRECTAMENTE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 10. EXPORTAR PREDICCIONES A EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con predicciones\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Real': y_test.map({0: 'No', 1: 'S√≠'}),\n",
    "    'Prediccion': [('S√≠' if p == 1 else 'No') for p in y_pred_best],\n",
    "    'Correcto': y_test == y_pred_best\n",
    "})\n",
    "\n",
    "# Agregar probabilidades si est√°n disponibles\n",
    "if y_pred_proba_best is not None:\n",
    "    predictions_df['Probabilidad_Si'] = y_pred_proba_best\n",
    "    predictions_df['Probabilidad_No'] = 1 - y_pred_proba_best\n",
    "\n",
    "# Agregar features originales\n",
    "X_test_original = X_test.reset_index(drop=True)\n",
    "predictions_df = pd.concat([predictions_df, X_test_original], axis=1)\n",
    "\n",
    "# Crear archivo Excel con m√∫ltiples hojas\n",
    "with pd.ExcelWriter('predicciones_pago_solar.xlsx', engine='openpyxl') as writer:\n",
    "    # Hoja 1: Predicciones\n",
    "    predictions_df.to_excel(writer, sheet_name='Predicciones', index=False)\n",
    "    \n",
    "    # Hoja 2: Resumen de m√©tricas\n",
    "    metrics_summary = pd.DataFrame([\n",
    "        {'M√©trica': 'Modelo', 'Valor': best_model_name},\n",
    "        {'M√©trica': 'Accuracy', 'Valor': f\"{results[best_model_name]['test_accuracy']:.4f}\"},\n",
    "        {'M√©trica': 'Precision', 'Valor': f\"{results[best_model_name]['precision']:.4f}\"},\n",
    "        {'M√©trica': 'Recall', 'Valor': f\"{results[best_model_name]['recall']:.4f}\"},\n",
    "        {'M√©trica': 'F1-Score', 'Valor': f\"{results[best_model_name]['f1_score']:.4f}\"},\n",
    "        {'M√©trica': 'AUC-ROC', 'Valor': f\"{results[best_model_name]['auc_roc']:.4f}\" if results[best_model_name]['auc_roc'] else 'N/A'},\n",
    "        {'M√©trica': 'Total Predicciones', 'Valor': len(predictions_df)},\n",
    "        {'M√©trica': 'Predicciones Correctas', 'Valor': predictions_df['Correcto'].sum()},\n",
    "        {'M√©trica': 'Predicciones Incorrectas', 'Valor': (~predictions_df['Correcto']).sum()}\n",
    "    ])\n",
    "    metrics_summary.to_excel(writer, sheet_name='Resumen M√©tricas', index=False)\n",
    "    \n",
    "    # Hoja 3: Matriz de confusi√≥n\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                        columns=['Predicho: No', 'Predicho: S√≠'],\n",
    "                        index=['Real: No', 'Real: S√≠'])\n",
    "    cm_df.to_excel(writer, sheet_name='Matriz Confusi√≥n')\n",
    "    \n",
    "    # Hoja 4: Comparaci√≥n de todos los modelos\n",
    "    comparison_df.to_excel(writer, sheet_name='Comparaci√≥n Modelos', index=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREDICCIONES EXPORTADAS A EXCEL\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚úì Archivo creado: predicciones_pago_solar.xlsx\")\n",
    "print(\"\\nHojas incluidas:\")\n",
    "print(\"  1. Predicciones - Detalle de cada predicci√≥n\")\n",
    "print(\"  2. Resumen M√©tricas - M√©tricas del mejor modelo\")\n",
    "print(\"  3. Matriz Confusi√≥n - Matriz de confusi√≥n\")\n",
    "print(\"  4. Comparaci√≥n Modelos - Comparaci√≥n de todos los modelos\")\n",
    "\n",
    "# Mostrar preview\n",
    "print(\"\\nPreview de predicciones:\")\n",
    "predictions_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 11. RESUMEN FINAL Y CONCLUSIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN FINAL DEL PROYECTO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä DATOS:\")\n",
    "print(f\"  - Total de registros: {len(df)}\")\n",
    "print(f\"  - Variables predictoras: {len(X.columns)}\")\n",
    "print(f\"  - Train/Test split: {len(X_train)}/{len(X_test)} (80%/20%)\")\n",
    "print(f\"  - Distribuci√≥n de clases: S√≠={y.sum()} ({y.mean()*100:.1f}%), No={len(y)-y.sum()} ({(1-y.mean())*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nü§ñ MODELOS ENTRENADOS:\")\n",
    "print(f\"  - Total de modelos: {len(models)}\")\n",
    "print(f\"  - Mejor modelo: {best_model_name}\")\n",
    "\n",
    "print(\"\\nüìà M√âTRICAS DEL MEJOR MODELO:\")\n",
    "print(f\"  - Accuracy (Test):  {results[best_model_name]['test_accuracy']:.4f}\")\n",
    "print(f\"  - Precision:        {results[best_model_name]['precision']:.4f}\")\n",
    "print(f\"  - Recall:           {results[best_model_name]['recall']:.4f}\")\n",
    "print(f\"  - F1-Score:         {results[best_model_name]['f1_score']:.4f}\")\n",
    "if results[best_model_name]['auc_roc']:\n",
    "    print(f\"  - AUC-ROC:          {results[best_model_name]['auc_roc']:.4f}\")\n",
    "print(f\"  - CV Accuracy:      {results[best_model_name]['cv_mean']:.4f} (+/- {results[best_model_name]['cv_std']:.4f})\")\n",
    "\n",
    "print(\"\\nüíæ ARCHIVOS GENERADOS:\")\n",
    "print(\"  ‚úì best_model_pago_solar.pkl\")\n",
    "print(\"  ‚úì scaler_pago_solar.pkl\")\n",
    "print(\"  ‚úì label_encoders_pago_solar.pkl\")\n",
    "print(\"  ‚úì model_info_pago_solar.json\")\n",
    "print(\"  ‚úì comparacion_modelos_pago_solar.xlsx\")\n",
    "print(\"  ‚úì predicciones_pago_solar.xlsx\")\n",
    "\n",
    "print(\"\\n‚úÖ CONCLUSIONES:\")\n",
    "accuracy = results[best_model_name]['test_accuracy']\n",
    "if accuracy >= 0.90:\n",
    "    print(\"  - El modelo tiene un EXCELENTE desempe√±o (‚â•90% accuracy)\")\n",
    "elif accuracy >= 0.80:\n",
    "    print(\"  - El modelo tiene un BUEN desempe√±o (‚â•80% accuracy)\")\n",
    "elif accuracy >= 0.70:\n",
    "    print(\"  - El modelo tiene un desempe√±o ACEPTABLE (‚â•70% accuracy)\")\n",
    "else:\n",
    "    print(\"  - El modelo tiene un desempe√±o BAJO (<70% accuracy)\")\n",
    "    print(\"  - Se recomienda revisar features o probar otros modelos\")\n",
    "\n",
    "f1 = results[best_model_name]['f1_score']\n",
    "if f1 >= 0.85:\n",
    "    print(\"  - El balance Precision/Recall es EXCELENTE (F1 ‚â•0.85)\")\n",
    "elif f1 >= 0.75:\n",
    "    print(\"  - El balance Precision/Recall es BUENO (F1 ‚â•0.75)\")\n",
    "else:\n",
    "    print(\"  - El balance Precision/Recall puede mejorarse (F1 <0.75)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ PROYECTO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
