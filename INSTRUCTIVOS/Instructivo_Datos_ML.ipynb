{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6712edca",
   "metadata": {},
   "source": [
    "## **De Excel a Python: Análisis Inteligente de Datos con Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be302f12",
   "metadata": {},
   "source": [
    "## *Instructivo para manejo de librerías y flujo de trabajo para la elaboración y ejecución de proyectos con técnicas de machine learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3fed2e",
   "metadata": {},
   "source": [
    "## **ÍNDICE**\n",
    "\n",
    "1. **Librería Pandas**\n",
    "   - 1.1 Principales comandos de pandas\n",
    "   - 1.2 ¿Qué es `df`?\n",
    "   - 1.3 Ejemplo simple con pandas\n",
    "\n",
    "2. **Librería NumPy**\n",
    "   - 2.1 ¿Qué es NumPy?\n",
    "   - 2.2 Ejemplo simple con NumPy\n",
    "\n",
    "3. **Librería SciPy**\n",
    "   - 3.1 ¿Qué es SciPy?\n",
    "   - 3.2 ¿Qué es scipy.stats?\n",
    "   - 3.3 Ejemplo simple con SciPy (scipy.stats)\n",
    "\n",
    "4. **Librería Matplotlib**\n",
    "   - 4.1 Principales comandos de Matplotlib\n",
    "   - 4.2 ¿Qué es Matplotlib?\n",
    "   - 4.3 Ejemplo simple con Matplotlib\n",
    "\n",
    "5. **Otras librerías de visualización**\n",
    "   - 5.1 Plotly\n",
    "   - 5.2 Seaborn\n",
    "\n",
    "6. **Librería scikit-learn (sklearn)**\n",
    "   - 6.1 Principales comandos de scikit-learn\n",
    "   - 6.2 ¿Qué es StandardScaler?\n",
    "   - 6.3 ¿Qué es LabelEncoder?\n",
    "   - 6.4 ¿Qué es scikit-learn?\n",
    "   - 6.5 `np.random.seed(42)` - Explicación\n",
    "   - 6.6 Ejemplo simple con scikit-learn (Regresión)\n",
    "   - 6.7 Ejemplo simple con scikit-learn - Clasificación con Random Forest\n",
    "\n",
    "7. **Librería openpyxl**\n",
    "   - 7.1 Principales comandos de openpyxl\n",
    "   - 7.2 ¿Qué es openpyxl?\n",
    "   - 7.3 Ejemplo simple con openpyxl\n",
    "\n",
    "8. **Modelos PKL (Pickle) y Joblib**\n",
    "   - 8.1 ¿Qué son los modelos PKL (Pickle) y por qué se guardan?\n",
    "   - 8.2 ¿Qué es Pickle?\n",
    "   - 8.3 ¿Qué contiene un modelo PKL?\n",
    "   - 8.4 Alternativas a Pickle\n",
    "   - 8.5 ¿Qué es un Framework?\n",
    "   - 8.6 Ejemplo práctico: Guardar y cargar modelos PKL\n",
    "   - 8.7 Flujo completo de guardado y carga\n",
    "   - 8.8 Ejemplo de despliegue en producción\n",
    "   - 8.9 Casos de uso comunes para modelos PKL\n",
    "   - 8.10 Mejores prácticas\n",
    "   - 8.11 Resumen final: Pickle vs Joblib\n",
    "\n",
    "9. **Librería PyTorch (Opcional)**\n",
    "   - 9.1 Principales comandos de PyTorch\n",
    "   - 9.2 ¿Qué es PyTorch?\n",
    "   - 9.3 Ejemplo simple con PyTorch\n",
    "   - 9.4 Comparación: PyTorch vs scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313630a",
   "metadata": {},
   "source": [
    "Este instructivo tiene como objetivo servir como guía de referencia para el curso **Excel a Python: Análisis Inteligente de Datos con Machine Learning**.\n",
    "\n",
    "A lo largo del curso se realizará una revisión práctica de las librerías **Pandas**, **NumPy**, **Scikit-learn** y **openpyxl**, enfocada en la construcción, entrenamiento y despliegue de modelos de Machine Learning directamente integrados con Excel.\n",
    "\n",
    "También se explicará la estructura y uso de los archivos binarios que almacenan modelos entrenados, tales como `.pkl` y `.joblib`, detallando buenas prácticas para su manejo, carga y actualización.\n",
    "\n",
    "De manera opcional, se incluirán ejemplos introductorios con la librería **PyTorch**, orientados a quienes deseen explorar modelos más avanzados basados en redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0c850",
   "metadata": {},
   "source": [
    "## **1. Principales comandos de Pandas**\n",
    "\n",
    "Pandas es una librería de Python para manipulación de datos y análisis. A continuación se presentan los comandos más utilizados:\n",
    "\n",
    "### **Lectura y escritura de datos**\n",
    "- `pd.read_csv()` - Leer archivos CSV\n",
    "- `pd.read_excel()` - Leer archivos Excel\n",
    "- `pd.read_json()` - Leer archivos JSON\n",
    "\n",
    "**Ejemplo de JSON:**\n",
    "```json\n",
    "{\n",
    "  \"nombre\": \"Juan\",\n",
    "  \"edad\": 30,\n",
    "  \"ciudad\": \"Madrid\",\n",
    "  \"hobbies\": [\"lectura\", \"programación\", \"deportes\"],\n",
    "  \"activo\": true\n",
    "}\n",
    "```\n",
    "\n",
    "- `df.to_csv()` - Guardar a CSV\n",
    "- `df.to_excel()` - Guardar a Excel\n",
    "\n",
    "### **Exploración y visualización de datos**\n",
    "- `df.head()` - Primeras filas\n",
    "- `df.tail()` - Últimas filas\n",
    "- `df.info()` - Información del DataFrame\n",
    "- `df.describe()` - Estadísticas descriptivas\n",
    "- `df.shape` - Dimensiones (filas, columnas)\n",
    "- `df.columns` - Nombres de columnas\n",
    "- `df.dtypes` - Tipos de datos\n",
    "\n",
    "### **Selección y filtrado**\n",
    "- `df[columna]` - Seleccionar columna\n",
    "- `df[['col1', 'col2']]` - Seleccionar múltiples columnas\n",
    "- `df.loc[]` - Selección por etiquetas (A, B, C, nombres personalizados, etc.)\n",
    "- `df.iloc[]` - Selección por posición (0, 1, 2, 3...)\n",
    "- `df.query()` - Filtrado con expresiones\n",
    "\n",
    "### **Manipulación de datos**\n",
    "- `df.drop()` - Eliminar filas/columnas\n",
    "- `df.rename()` - Renombrar columnas\n",
    "- `df.sort_values()` - Ordenar valores\n",
    "- `df.groupby()` - Agrupar datos\n",
    "- `df.pivot_table()` - Crear tabla dinámica\n",
    "- `df.merge()` - Combinar DataFrames\n",
    "- `df.concat()` - Concatenar DataFrames\n",
    "\n",
    "### **Limpieza de datos**\n",
    "- `df.isna()` / `df.isnull()` - Detectar valores nulos\n",
    "- `df.dropna()` - Eliminar valores nulos\n",
    "- `df.fillna()` - Rellenar valores nulos\n",
    "- `df.duplicated()` - Detectar duplicados\n",
    "- `df.drop_duplicates()` - Eliminar duplicados\n",
    "\n",
    "### **Operaciones estadísticas**\n",
    "- `df.mean()` - Media\n",
    "- `df.median()` - Mediana\n",
    "- `df.std()` - Desviación estándar\n",
    "- `df.sum()` - Suma\n",
    "- `df.count()` - Conteo\n",
    "- `df.corr()` - Correlación\n",
    "\n",
    "### **Transformaciones**\n",
    "- `df.apply()` - Aplicar función\n",
    "- `df.map()` - Mapear valores\n",
    "- `df.replace()` - Reemplazar valores\n",
    "- `df.astype()` - Cambiar tipo de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80244fee",
   "metadata": {},
   "source": [
    "En pandas, `df` es una convención para referirse a un DataFrame, y `pd` para referirse a la librería Pandas ya importada. \n",
    "\n",
    "## **1.2 ¿Qué es `df`?**\n",
    "\n",
    "`df` es una variable que típicamente contiene un DataFrame de pandas, una estructura bidimensional con filas y columnas (similar a una hoja de Excel o una tabla SQL).\n",
    "\n",
    "### Características principales:\n",
    "\n",
    "1. Estructura de datos: tabla con filas (observaciones) y columnas (variables/features)\n",
    "2. Tipos de datos: cada columna puede tener un tipo diferente (números, texto, fechas, etc.)\n",
    "3. Operaciones: panda permite manipular, filtrar, transformar y analizar datos\n",
    "\n",
    "### Ejemplo típico de uso:\n",
    "\n",
    "```python\n",
    "# Cargar datos desde un archivo Excel\n",
    "df = pd.read_excel('archivo.xlsx')\n",
    "\n",
    "# Ver las primeras filas\n",
    "df.head()\n",
    "\n",
    "# Ver información del DataFrame\n",
    "df.info()\n",
    "\n",
    "# Ver estadísticas descriptivas\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "En el proyecto, `df` se usa para almacenar los datos de paneles solares, y para cualquier otro proyecto indica los datos que serán cargados desde Excel. El nombre puede variar o se puede usar cualquier letra. Es recomendable no usar `i` ni `j` ya que están reservadas para números complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149551f0",
   "metadata": {},
   "source": [
    "### **1.3 Ejemplo simple con Pandas**\n",
    "\n",
    "A continuación se presenta un ejemplo básico y fácil de entender para operar con pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f9d325e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame creado:\n",
      "   Nombre  Edad     Ciudad  Salario\n",
      "0     Ana    25     Madrid     3000\n",
      "1    Luis    30  Barcelona     3500\n",
      "2   María    28   Valencia     3200\n",
      "3  Carlos    35     Madrid     4000\n",
      "4   Laura    22    Sevilla     2800\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EJEMPLO SIMPLE CON PANDAS\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Crear un DataFrame simple desde un diccionario\n",
    "# Un diccionario es un tipo de variable que almacena datos en forma de clave-valor\n",
    "datos = {\n",
    "    'Nombre': ['Ana', 'Luis', 'María', 'Carlos', 'Laura'],\n",
    "    'Edad': [25, 30, 28, 35, 22],\n",
    "    'Ciudad': ['Madrid', 'Barcelona', 'Valencia', 'Madrid', 'Sevilla'],\n",
    "    'Salario': [3000, 3500, 3200, 4000, 2800]\n",
    "}\n",
    "\n",
    "# 2. Crear el DataFrame con los datos del diccionario\n",
    "df = pd.DataFrame(datos)\n",
    "\n",
    "print(\"DataFrame creado:\")\n",
    "print(df)\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "783386cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 3 filas:\n",
      "  Nombre  Edad     Ciudad  Salario\n",
      "0    Ana    25     Madrid     3000\n",
      "1   Luis    30  Barcelona     3500\n",
      "2  María    28   Valencia     3200\n",
      "\n",
      "Información del DataFrame:\n",
      "Filas: 5, Columnas: 4\n",
      "\n",
      "Estadísticas básicas:\n",
      "            Edad      Salario\n",
      "count   5.000000     5.000000\n",
      "mean   28.000000  3300.000000\n",
      "std     4.949747   469.041576\n",
      "min    22.000000  2800.000000\n",
      "25%    25.000000  3000.000000\n",
      "50%    28.000000  3200.000000\n",
      "75%    30.000000  3500.000000\n",
      "max    35.000000  4000.000000\n"
     ]
    }
   ],
   "source": [
    "# 2. Ver información básica del DataFrame\n",
    "print(\"Primeras 3 filas:\")\n",
    "print(df.head(3))  # Imprime las primeras 3 filas del DataFrame\n",
    "\n",
    "print(\"\\nInformación del DataFrame:\")\n",
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")  # Imprime el número de filas y columnas del DataFrame\n",
    "\n",
    "print(\"\\nEstadísticas básicas:\")\n",
    "print(df.describe())  # Imprime las estadísticas descriptivas del DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bfe98b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solo la columna 'Nombre':\n",
      "0       Ana\n",
      "1      Luis\n",
      "2     María\n",
      "3    Carlos\n",
      "4     Laura\n",
      "Name: Nombre, dtype: object\n",
      "\n",
      "Múltiples columnas:\n",
      "   Nombre  Edad  Salario\n",
      "0     Ana    25     3000\n",
      "1    Luis    30     3500\n",
      "2   María    28     3200\n",
      "3  Carlos    35     4000\n",
      "4   Laura    22     2800\n"
     ]
    }
   ],
   "source": [
    "# 3. Seleccionar columnas\n",
    "print(\"Solo la columna 'Nombre':\") \n",
    "print(df['Nombre'])  # Imprime la columna 'Nombre' del DataFrame\n",
    "\n",
    "print(\"\\nMúltiples columnas:\")\n",
    "print(df[['Nombre', 'Edad', 'Salario']])  # Imprime las columnas 'Nombre', 'Edad' y 'Salario' del DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "009eb6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personas mayores de 27 años:\n",
      "   Nombre  Edad     Ciudad  Salario\n",
      "1    Luis    30  Barcelona     3500\n",
      "2   María    28   Valencia     3200\n",
      "3  Carlos    35     Madrid     4000\n",
      "\n",
      "Personas de Madrid:\n",
      "   Nombre  Edad  Ciudad  Salario\n",
      "0     Ana    25  Madrid     3000\n",
      "3  Carlos    35  Madrid     4000\n"
     ]
    }
   ],
   "source": [
    "# 4. Filtrar datos\n",
    "print(\"Personas mayores de 27 años:\")\n",
    "print(df[df['Edad'] > 27])  # Imprime las filas del DataFrame donde la columna 'Edad' es mayor a 27\n",
    "\n",
    "print(\"\\nPersonas de Madrid:\")\n",
    "print(df[df['Ciudad'] == 'Madrid'])  # Imprime las filas del DataFrame donde la columna 'Ciudad' es igual a 'Madrid'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b2e05012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salario promedio: 3300.0\n",
      "Edad promedio: 28.0\n",
      "Salario máximo: 4000\n",
      "\n",
      "Agrupar por ciudad y calcular salario promedio:\n",
      "Ciudad\n",
      "Barcelona    3500.0\n",
      "Madrid       3500.0\n",
      "Sevilla      2800.0\n",
      "Valencia     3200.0\n",
      "Name: Salario, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 5. Operaciones básicas\n",
    "print(\"Salario promedio:\", df['Salario'].mean())  # Imprime el promedio del salario del DataFrame\n",
    "print(\"Edad promedio:\", df['Edad'].mean())  # Imprime el promedio de la edad del DataFrame\n",
    "print(\"Salario máximo:\", df['Salario'].max())  # Imprime el máximo salario del DataFrame\n",
    "\n",
    "print(\"\\nAgrupar por ciudad y calcular salario promedio:\")\n",
    "print(df.groupby('Ciudad')['Salario'].mean())  # Imprime el promedio de los salarios por ciudad del DataFrame    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3433ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordenado por Salario (de mayor a menor):\n",
      "   Nombre  Edad     Ciudad  Salario\n",
      "3  Carlos    35     Madrid     4000\n",
      "1    Luis    30  Barcelona     3500\n",
      "2   María    28   Valencia     3200\n",
      "0     Ana    25     Madrid     3000\n",
      "4   Laura    22    Sevilla     2800\n"
     ]
    }
   ],
   "source": [
    "# 6. Ordenar datos\n",
    "print(\"Ordenado por Salario (de mayor a menor):\")\n",
    "print(df.sort_values('Salario', ascending=False))  # Imprime el DataFrame ordenado por el salario de mayor a menor   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2af455",
   "metadata": {},
   "source": [
    "## **2. ¿Qué es NumPy?**\n",
    "\n",
    "NumPy (Numerical Python) es una biblioteca fundamental de Python para computación científica y análisis numérico.\n",
    "\n",
    "### **Características principales:**\n",
    "\n",
    "1. **Arrays multidimensionales**: Estructura de datos principal llamada `ndarray` (N-dimensional array) que permite trabajar con matrices nxm (n filas x m columnas) y vectores (1xm vector fila, o nx1 vector columna) de manera eficiente\n",
    "2. **Operaciones matemáticas**: Funciones optimizadas para operaciones matemáticas, algebraicas y estadísticas\n",
    "3. **Rendimiento**: Implementado en C, es mucho más rápido que las listas de Python para operaciones numéricas\n",
    "4. **Base para otras librerías**: Pandas, scikit-learn y muchas otras librerías de ciencia de datos están construidas sobre NumPy\n",
    "\n",
    "### **Conceptos clave:**\n",
    "\n",
    "- **Array (`np.array`)**: Estructura de datos principal, similar a una lista pero más eficiente. Un array es un arreglo donde se guardan los datos numéricos\n",
    "- **Operaciones vectorizadas**: Permite realizar operaciones en arrays completos sin bucles, por ejemplo multiplicación de filas por columnas como en álgebra lineal, o operación punto a punto entre vectores o matrices\n",
    "- **Broadcasting**: Permite operaciones entre arrays de diferentes tamaños\n",
    "- **Indexación avanzada**: Acceso eficiente a elementos usando índices, máscaras booleanas, etc.\n",
    "\n",
    "### Ejemplo típico de uso:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Crear un array\n",
    "numeros = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Operaciones matemáticas\n",
    "print(numeros * 2)  # Multiplicar todos los elementos por 2\n",
    "print(numeros.mean())  # Calcular la media\n",
    "print(np.sort(numeros))  # Ordenar el array\n",
    "```\n",
    "\n",
    "En el proyecto, NumPy se usa para operaciones numéricas, cálculos matemáticos y como base para las operaciones de pandas y scikit-learn.\n",
    "\n",
    "### **2.1 Ejemplo simple con NumPy**\n",
    "\n",
    "A continuación se presenta un ejemplo básico para trabajar con NumPy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "177cfdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array original de salarios:\n",
      "[3000 3500 3200 4000 2800]\n",
      "\n",
      "Ordenado de menor a mayor:\n",
      "[2800 3000 3200 3500 4000]\n",
      "\n",
      "Ordenado de mayor a menor (usando índices):\n",
      "[4000 3500 3200 3000 2800]\n",
      "\n",
      "Ordenado de mayor a menor (método directo):\n",
      "[4000 3500 3200 3000 2800]\n"
     ]
    }
   ],
   "source": [
    "# 1. Ordenar datos con NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Crear un array de ejemplo con los salarios\n",
    "salarios = np.array([3000, 3500, 3200, 4000, 2800])\n",
    "\n",
    "print(\"Array original de salarios:\")\n",
    "print(salarios)\n",
    "\n",
    "print(\"\\nOrdenado de menor a mayor:\")\n",
    "print(np.sort(salarios))  # Ordena el array de menor a mayor\n",
    "\n",
    "print(\"\\nOrdenado de mayor a menor (usando índices):\")\n",
    "indices_ordenados = np.argsort(salarios)[::-1]  # Obtiene los índices ordenados de mayor a menor\n",
    "print(salarios[indices_ordenados])  # Imprime el array ordenado usando los índices\n",
    "\n",
    "print(\"\\nOrdenado de mayor a menor (método directo):\")\n",
    "print(-np.sort(-salarios))  # Ordena de mayor a menor multiplicando por -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842a630",
   "metadata": {},
   "source": [
    "## **3. ¿Qué es SciPy?**\n",
    "\n",
    "SciPy (Scientific Python) es una biblioteca de Python para computación científica y análisis estadístico. Está construida sobre NumPy y proporciona funciones adicionales para optimización, integración, interpolación, procesamiento de señales, álgebra lineal y estadística.\n",
    "\n",
    "### **Características principales:**\n",
    "\n",
    "1. **Módulos especializados**: SciPy está organizada en submódulos especializados para diferentes áreas científicas\n",
    "2. **Estadística avanzada**: Funciones para análisis estadístico, pruebas de hipótesis y distribuciones de probabilidad\n",
    "3. **Optimización**: Algoritmos para optimización matemática y búsqueda de mínimos/máximos\n",
    "4. **Integración numérica**: Métodos para calcular integrales numéricas\n",
    "5. **Procesamiento de señales**: Herramientas para análisis de señales y filtrado\n",
    "6. **Álgebra lineal**: Funciones avanzadas de álgebra lineal más allá de NumPy\n",
    "\n",
    "### **Módulos principales de SciPy:**\n",
    "\n",
    "- **`scipy.stats`**: Estadística y distribuciones de probabilidad\n",
    "- **`scipy.optimize`**: Optimización y búsqueda de raíces\n",
    "- **`scipy.integrate`**: Integración numérica\n",
    "- **`scipy.interpolate`**: Interpolación de datos\n",
    "- **`scipy.linalg`**: Álgebra lineal avanzada\n",
    "- **`scipy.signal`**: Procesamiento de señales\n",
    "\n",
    "### **Conceptos clave:**\n",
    "\n",
    "- **Distribuciones de probabilidad**: Representaciones matemáticas de variables aleatorias (normal, binomial, etc.)\n",
    "- **Pruebas estadísticas**: Métodos para probar hipótesis sobre datos\n",
    "- **Estadísticas descriptivas**: Medidas que resumen características de los datos\n",
    "\n",
    "### Ejemplo típico de uso:\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Generar datos con distribución normal\n",
    "datos = np.random.normal(100, 15, 1000)\n",
    "\n",
    "# Calcular estadísticas\n",
    "media = stats.mean(datos)\n",
    "desviacion = stats.std(datos)\n",
    "\n",
    "# Prueba de normalidad\n",
    "estadistico, p_valor = stats.normaltest(datos)\n",
    "```\n",
    "\n",
    "En el proyecto, SciPy se usa principalmente para análisis estadístico avanzado, pruebas de hipótesis y trabajar con distribuciones de probabilidad cuando se necesita más que las funciones básicas de NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9367c3",
   "metadata": {},
   "source": [
    "### **3.2 ¿Qué es scipy.stats?**\n",
    "\n",
    "**scipy.stats** es el submódulo de SciPy que proporciona funciones para análisis estadístico y trabajo con distribuciones de probabilidad.\n",
    "\n",
    "### **Características principales:**\n",
    "\n",
    "1. **Distribuciones de probabilidad**: Más de 100 distribuciones continuas y discretas (normal, binomial, exponencial, etc.)\n",
    "2. **Estadísticas descriptivas**: Funciones para calcular medidas estadísticas (media, mediana, moda, percentiles, etc.)\n",
    "3. **Pruebas estadísticas**: Pruebas de hipótesis (t-test, chi-cuadrado, ANOVA, etc.)\n",
    "4. **Funciones de densidad**: PDF (Probability Density Function) y CDF (Cumulative Distribution Function)\n",
    "5. **Generación de muestras aleatorias**: Generar datos aleatorios siguiendo distribuciones específicas\n",
    "\n",
    "### **Funciones más utilizadas:**\n",
    "\n",
    "- **Estadísticas descriptivas**:\n",
    "  - `stats.mean()` - Media aritmética\n",
    "  - `stats.median()` - Mediana\n",
    "  - `stats.mode()` - Moda\n",
    "  - `stats.std()` - Desviación estándar\n",
    "  - `stats.percentile()` - Percentiles\n",
    "\n",
    "- **Distribuciones**:\n",
    "  - `stats.norm` - Distribución normal\n",
    "  - `stats.binom` - Distribución binomial\n",
    "  - `stats.expon` - Distribución exponencial\n",
    "  - `stats.uniform` - Distribución uniforme\n",
    "\n",
    "- **Pruebas estadísticas**:\n",
    "  - `stats.ttest_1samp()` - Prueba t de una muestra\n",
    "  - `stats.ttest_ind()` - Prueba t de dos muestras independientes\n",
    "  - `stats.normaltest()` - Prueba de normalidad\n",
    "  - `stats.chi2_contingency()` - Prueba chi-cuadrado\n",
    "\n",
    "### **Ejemplo típico de uso:**\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "datos = np.array([23, 25, 28, 30, 32, 35, 38, 40, 42, 45])\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "media = stats.mean(datos)\n",
    "mediana = stats.median(datos)\n",
    "desviacion = stats.std(datos)\n",
    "\n",
    "# Prueba de normalidad\n",
    "estadistico, p_valor = stats.normaltest(datos)\n",
    "```\n",
    "\n",
    "En el proyecto, `scipy.stats` se usa para análisis estadístico más avanzado que lo que proporciona NumPy o Pandas, especialmente para pruebas de hipótesis y trabajo con distribuciones de probabilidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b1954",
   "metadata": {},
   "source": [
    "### **3.3 Ejemplo simple con SciPy (scipy.stats)**\n",
    "\n",
    "A continuación se presenta un ejemplo básico y fácil de entender para operar con SciPy, específicamente con el módulo `scipy.stats`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb198df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EJEMPLO SIMPLE CON SCIPY (SCIPY.STATS)\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EJEMPLO: ANÁLISIS ESTADÍSTICO CON SCIPY.STATS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Crear datos de ejemplo (simulando calificaciones de estudiantes)\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "calificaciones = np.random.normal(75, 10, 50)  # Media=75, Desviación=10, 50 estudiantes\n",
    "calificaciones = np.clip(calificaciones, 0, 100)  # Limitar entre 0 y 100\n",
    "\n",
    "print(\"\\n1. Datos de ejemplo creados (calificaciones de estudiantes):\")\n",
    "print(f\"   Número de estudiantes: {len(calificaciones)}\")\n",
    "print(f\"   Primeras 10 calificaciones: {calificaciones[:10]}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Estadísticas descriptivas básicas\n",
    "media = stats.mean(calificaciones)  # Media aritmética\n",
    "mediana = stats.median(calificaciones)  # Mediana\n",
    "desviacion = stats.std(calificaciones)  # Desviación estándar\n",
    "percentil_25 = stats.scoreatpercentile(calificaciones, 25)  # Percentil 25 (Q1)\n",
    "percentil_75 = stats.scoreatpercentile(calificaciones, 75)  # Percentil 75 (Q3)\n",
    "\n",
    "print(\"2. Estadísticas descriptivas:\")\n",
    "print(f\"   Media: {media:.2f}\")\n",
    "print(f\"   Mediana: {mediana:.2f}\")\n",
    "print(f\"   Desviación estándar: {desviacion:.2f}\")\n",
    "print(f\"   Percentil 25 (Q1): {percentil_25:.2f}\")\n",
    "print(f\"   Percentil 75 (Q3): {percentil_75:.2f}\")\n",
    "print(f\"   Rango intercuartil (IQR): {percentil_75 - percentil_25:.2f}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa046a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prueba de normalidad (verificar si los datos siguen una distribución normal)\n",
    "estadistico, p_valor = stats.normaltest(calificaciones)  # Prueba de D'Agostino y Pearson\n",
    "\n",
    "print(\"3. Prueba de normalidad:\")\n",
    "print(f\"   Estadístico de prueba: {estadistico:.4f}\")\n",
    "print(f\"   P-valor: {p_valor:.4f}\")\n",
    "\n",
    "if p_valor > 0.05:\n",
    "    print(\"   ✓ Los datos parecen seguir una distribución normal (p > 0.05)\")\n",
    "else:\n",
    "    print(\"   ✗ Los datos NO siguen una distribución normal (p ≤ 0.05)\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0547d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Trabajar con distribuciones de probabilidad\n",
    "# Ajustar una distribución normal a los datos\n",
    "media_estimada, desviacion_estimada = stats.norm.fit(calificaciones)\n",
    "\n",
    "print(\"4. Ajuste de distribución normal:\")\n",
    "print(f\"   Media estimada: {media_estimada:.2f}\")\n",
    "print(f\"   Desviación estándar estimada: {desviacion_estimada:.2f}\")\n",
    "\n",
    "# Crear una distribución normal con los parámetros estimados\n",
    "distribucion_normal = stats.norm(loc=media_estimada, scale=desviacion_estimada)\n",
    "\n",
    "# Calcular probabilidades\n",
    "probabilidad_aprobado = 1 - distribucion_normal.cdf(60)  # Probabilidad de calificación >= 60\n",
    "probabilidad_excelente = 1 - distribucion_normal.cdf(90)  # Probabilidad de calificación >= 90\n",
    "\n",
    "print(f\"\\n   Probabilidades basadas en la distribución normal:\")\n",
    "print(f\"   Probabilidad de aprobar (≥60): {probabilidad_aprobado*100:.2f}%\")\n",
    "print(f\"   Probabilidad de excelente (≥90): {probabilidad_excelente*100:.2f}%\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bdbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Comparar dos grupos (prueba t de dos muestras independientes)\n",
    "# Simular calificaciones de dos grupos diferentes (grupo A y grupo B)\n",
    "np.random.seed(42)\n",
    "grupo_a = np.random.normal(75, 10, 30)\n",
    "grupo_a = np.clip(grupo_a, 0, 100)\n",
    "\n",
    "grupo_b = np.random.normal(80, 12, 30)  # Grupo B con media ligeramente mayor\n",
    "grupo_b = np.clip(grupo_b, 0, 100)\n",
    "\n",
    "# Prueba t de dos muestras independientes\n",
    "estadistico_t, p_valor_t = stats.ttest_ind(grupo_a, grupo_b)\n",
    "\n",
    "print(\"5. Comparación de dos grupos (Prueba t):\")\n",
    "print(f\"   Grupo A - Media: {stats.mean(grupo_a):.2f}, Desviación: {stats.std(grupo_a):.2f}\")\n",
    "print(f\"   Grupo B - Media: {stats.mean(grupo_b):.2f}, Desviación: {stats.std(grupo_b):.2f}\")\n",
    "print(f\"\\n   Estadístico t: {estadistico_t:.4f}\")\n",
    "print(f\"   P-valor: {p_valor_t:.4f}\")\n",
    "\n",
    "if p_valor_t < 0.05:\n",
    "    print(\"   ✓ Hay diferencia significativa entre los grupos (p < 0.05)\")\n",
    "else:\n",
    "    print(\"   ✗ No hay diferencia significativa entre los grupos (p ≥ 0.05)\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Generar datos aleatorios siguiendo una distribución específica\n",
    "# Generar 100 valores siguiendo una distribución normal con media=70 y desviación=15\n",
    "datos_generados = stats.norm.rvs(loc=70, scale=15, size=100, random_state=42)\n",
    "\n",
    "print(\"6. Generación de datos aleatorios:\")\n",
    "print(f\"   Datos generados: {len(datos_generados)} valores\")\n",
    "print(f\"   Media de datos generados: {stats.mean(datos_generados):.2f}\")\n",
    "print(f\"   Desviación estándar: {stats.std(datos_generados):.2f}\")\n",
    "print(f\"   Primeros 10 valores: {datos_generados[:10]}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Calcular intervalos de confianza\n",
    "# Intervalo de confianza del 95% para la media\n",
    "nivel_confianza = 0.95\n",
    "intervalo_confianza = stats.t.interval(\n",
    "    nivel_confianza, \n",
    "    len(calificaciones) - 1,  # Grados de libertad\n",
    "    loc=media,  # Media muestral\n",
    "    scale=stats.sem(calificaciones)  # Error estándar de la media\n",
    ")\n",
    "\n",
    "print(\"7. Intervalo de confianza para la media:\")\n",
    "print(f\"   Media muestral: {media:.2f}\")\n",
    "print(f\"   Intervalo de confianza del 95%: [{intervalo_confianza[0]:.2f}, {intervalo_confianza[1]:.2f}]\")\n",
    "print(f\"   Interpretación: Con 95% de confianza, la media poblacional está entre {intervalo_confianza[0]:.2f} y {intervalo_confianza[1]:.2f}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae590f16",
   "metadata": {},
   "source": [
    "## **4. Principales comandos de Matplotlib**\n",
    "\n",
    "Matplotlib es una librería de Python para crear visualizaciones y gráficos. A continuación se presentan los comandos más utilizados:\n",
    "\n",
    "### **Importación básica**\n",
    "- `import matplotlib.pyplot as plt` - Importar matplotlib (convención estándar)\n",
    "- `%matplotlib inline` - Mostrar gráficos en notebooks Jupyter\n",
    "\n",
    "### **Creación de gráficos básicos**\n",
    "- `plt.plot(x, y)` - Gráfico de línea\n",
    "- `plt.scatter(x, y)` - Gráfico de dispersión (puntos)\n",
    "- `plt.bar(x, y)` - Gráfico de barras verticales\n",
    "- `plt.barh(x, y)` - Gráfico de barras horizontales\n",
    "- `plt.hist(data)` - Histograma\n",
    "- `plt.boxplot(data)` - Diagrama de caja (boxplot)\n",
    "- `plt.pie(values, labels=labels)` - Gráfico circular (pie chart)\n",
    "\n",
    "### **Configuración de gráficos**\n",
    "- `plt.title('Título')` - Agregar título al gráfico\n",
    "- `plt.xlabel('Etiqueta X')` - Etiqueta del eje X\n",
    "- `plt.ylabel('Etiqueta Y')` - Etiqueta del eje Y\n",
    "- `plt.legend()` - Mostrar leyenda\n",
    "- `plt.grid(True)` - Mostrar cuadrícula\n",
    "- `plt.xlim(min, max)` - Límites del eje X\n",
    "- `plt.ylim(min, max)` - Límites del eje Y\n",
    "\n",
    "### **Múltiples gráficos**\n",
    "- `plt.subplot(rows, cols, index)` - Crear subgráficos\n",
    "- `plt.figure(figsize=(width, height))` - Tamaño de la figura\n",
    "- `plt.subplots(nrows, ncols)` - Crear múltiples subgráficos a la vez\n",
    "\n",
    "### **Personalización**\n",
    "- `plt.color` - Especificar color ('red', 'blue', '#FF5733', etc.)\n",
    "- `plt.linestyle` - Estilo de línea ('-', '--', '-.', ':')\n",
    "- `plt.marker` - Marcador de puntos ('o', 's', '^', '*', etc.)\n",
    "- `plt.linewidth` o `plt.lw` - Grosor de línea\n",
    "- `plt.alpha` - Transparencia (0.0 a 1.0)\n",
    "\n",
    "### **Guardar y mostrar**\n",
    "- `plt.savefig('nombre.png')` - Guardar gráfico como imagen\n",
    "- `plt.show()` - Mostrar el gráfico\n",
    "- `plt.close()` - Cerrar la figura actual\n",
    "\n",
    "### **Estilos y temas**\n",
    "- `plt.style.use('ggplot')` - Usar estilo predefinido\n",
    "- `plt.style.available` - Ver estilos disponibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434f173",
   "metadata": {},
   "source": [
    "### **4.2 ¿Qué es Matplotlib?**\n",
    "\n",
    "**Matplotlib** es una biblioteca de Python para crear visualizaciones y gráficos estáticos, animados e interactivos.\n",
    "\n",
    "### **Características principales:**\n",
    "\n",
    "1. **Visualización de datos**: Permite crear gráficos de línea, barras, dispersión, histogramas, etc.\n",
    "2. **Personalización**: Control total sobre colores, estilos, etiquetas y formato\n",
    "3. **Integración**: Funciona bien con NumPy y Pandas\n",
    "4. **Exportación**: Puede guardar gráficos en múltiples formatos (PNG, PDF, SVG, etc.)\n",
    "\n",
    "### **Conceptos clave:**\n",
    "\n",
    "- **Figure (`fig`)**: El contenedor completo que puede contener uno o más gráficos\n",
    "- **Axes (`ax`)**: Un gráfico individual dentro de una figura\n",
    "- **Plot**: La función que dibuja los datos en el gráfico\n",
    "- **Subplot**: Múltiples gráficos organizados en una cuadrícula\n",
    "\n",
    "### **Ejemplo típico de uso:**\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Crear datos\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Crear gráfico\n",
    "plt.plot(x, y)\n",
    "plt.title('Gráfico de Seno')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "En el proyecto, Matplotlib se usa para visualizar datos, resultados de modelos y crear gráficos para presentaciones o reportes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1507067",
   "metadata": {},
   "source": [
    "### **4.3 Ejemplo simple con Matplotlib**\n",
    "\n",
    "A continuación se presenta un ejemplo básico y fácil de entender para operar con Matplotlib:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c179b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EJEMPLO SIMPLE CON MATPLOTLIB\n",
    "# ============================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar para mostrar gráficos en el notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EJEMPLO: VISUALIZACIÓN CON MATPLOTLIB\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Crear datos de ejemplo\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 50)  # 50 puntos entre 0 y 10\n",
    "y = 2 * x + 3 + np.random.normal(0, 2, 50)  # Relación lineal con ruido\n",
    "\n",
    "print(\"\\n1. Datos de ejemplo creados:\")\n",
    "print(f\"   X: {len(x)} puntos\")\n",
    "print(f\"   Y: {len(y)} puntos\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Gráfico de línea básico\n",
    "plt.figure(figsize=(8, 5))  # Tamaño del gráfico (ancho, alto)\n",
    "plt.plot(x, y, 'o-', color='blue', linewidth=2, markersize=6, label='Datos')\n",
    "plt.title('Gráfico de Línea - Relación X vs Y', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Variable X', fontsize=12)\n",
    "plt.ylabel('Variable Y', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)  # Cuadrícula con transparencia\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"2. Gráfico de línea creado\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7607d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Gráfico de dispersión (scatter plot)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y, color='red', alpha=0.6, s=50)  # s = tamaño de los puntos\n",
    "plt.title('Gráfico de Dispersión - X vs Y', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Variable X', fontsize=12)\n",
    "plt.ylabel('Variable Y', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"3. Gráfico de dispersión creado\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gráfico de barras\n",
    "categorias = ['A', 'B', 'C', 'D', 'E']\n",
    "valores = [23, 45, 56, 78, 32]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(categorias, valores, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8'])\n",
    "plt.title('Gráfico de Barras - Valores por Categoría', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Categorías', fontsize=12)\n",
    "plt.ylabel('Valores', fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')  # Solo cuadrícula en eje Y\n",
    "plt.show()\n",
    "\n",
    "print(\"4. Gráfico de barras creado\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Histograma\n",
    "datos_aleatorios = np.random.normal(100, 15, 1000)  # Distribución normal\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(datos_aleatorios, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Histograma - Distribución de Datos', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Valores', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()\n",
    "\n",
    "print(\"5. Histograma creado\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Múltiples gráficos en una figura (subplots)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))  # 2 filas, 2 columnas\n",
    "\n",
    "# Gráfico 1: Línea\n",
    "axes[0, 0].plot(x, y, 'b-', linewidth=2)\n",
    "axes[0, 0].set_title('Gráfico de Línea')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 2: Dispersión\n",
    "axes[0, 1].scatter(x, y, color='red', alpha=0.6)\n",
    "axes[0, 1].set_title('Gráfico de Dispersión')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 3: Barras\n",
    "axes[1, 0].bar(categorias, valores, color='green', alpha=0.7)\n",
    "axes[1, 0].set_title('Gráfico de Barras')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Gráfico 4: Histograma\n",
    "axes[1, 1].hist(datos_aleatorios, bins=30, color='orange', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].set_title('Histograma')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()  # Ajustar espaciado entre gráficos\n",
    "plt.show()\n",
    "\n",
    "print(\"6. Múltiples gráficos creados en una figura\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Gráfico con datos de Pandas DataFrame\n",
    "df_ejemplo = pd.DataFrame({\n",
    "    'Mes': ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun'],\n",
    "    'Ventas': [100, 120, 140, 110, 150, 160],\n",
    "    'Gastos': [80, 90, 100, 85, 95, 105]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "x_pos = np.arange(len(df_ejemplo['Mes']))\n",
    "width = 0.35  # Ancho de las barras\n",
    "\n",
    "plt.bar(x_pos - width/2, df_ejemplo['Ventas'], width, label='Ventas', color='#2ecc71', alpha=0.8)\n",
    "plt.bar(x_pos + width/2, df_ejemplo['Gastos'], width, label='Gastos', color='#e74c3c', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Mes', fontsize=12)\n",
    "plt.ylabel('Cantidad', fontsize=12)\n",
    "plt.title('Ventas vs Gastos por Mes', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x_pos, df_ejemplo['Mes'])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()\n",
    "\n",
    "print(\"7. Gráfico con datos de DataFrame creado\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Guardar gráfico en archivo\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, 'o-', color='blue', linewidth=2, markersize=6)\n",
    "plt.title('Gráfico Guardado - X vs Y', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Variable X', fontsize=12)\n",
    "plt.ylabel('Variable Y', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('grafico_ejemplo.png', dpi=300, bbox_inches='tight')  # Guardar con alta resolución\n",
    "plt.show()\n",
    "\n",
    "print(\"8. Gráfico guardado como 'grafico_ejemplo.png'\")\n",
    "print(\"   (El archivo se guarda en el directorio actual)\")\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484cb29a",
   "metadata": {},
   "source": [
    "## **4. Otras librerías de visualización**\n",
    "\n",
    "### **4.1 Plotly**\n",
    "\n",
    "**Plotly** es una librería de Python para crear visualizaciones interactivas y dinámicas. A diferencia de Matplotlib, los gráficos de Plotly son interactivos: puedes hacer zoom, pan, hover para ver valores, y los gráficos se pueden exportar como HTML.\n",
    "\n",
    "**Características principales:**\n",
    "- Gráficos interactivos con zoom, pan y hover\n",
    "- Soporte para gráficos 3D\n",
    "- Integración con Dash para crear dashboards web\n",
    "- Exportación a HTML, PNG, PDF\n",
    "- Gráficos animados\n",
    "\n",
    "**Ejemplo básico:**\n",
    "```python\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'x': [1, 2, 3, 4], 'y': [10, 11, 12, 13]})\n",
    "fig = px.line(df, x='x', y='y', title='Gráfico Interactivo')\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "**Cuándo usar Plotly:**\n",
    "- Cuando necesitas gráficos interactivos para presentaciones web\n",
    "- Para dashboards y aplicaciones web\n",
    "- Cuando quieres que los usuarios exploren los datos interactivamente\n",
    "\n",
    "### **4.2 Seaborn**\n",
    "\n",
    "**Seaborn** es una librería de visualización estadística construida sobre Matplotlib. Proporciona una interfaz de alto nivel para crear gráficos estadísticos atractivos con menos código.\n",
    "\n",
    "**Características principales:**\n",
    "- Estilos visuales predefinidos y atractivos\n",
    "- Funciones especializadas para visualización estadística\n",
    "- Integración perfecta con Pandas DataFrames\n",
    "- Gráficos más informativos con menos código\n",
    "- Paletas de colores profesionales\n",
    "\n",
    "**Ejemplo básico:**\n",
    "```python\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'x': [1, 2, 3, 4], 'y': [10, 11, 12, 13]})\n",
    "sns.lineplot(data=df, x='x', y='y')\n",
    "```\n",
    "\n",
    "**Cuándo usar Seaborn:**\n",
    "- Para análisis exploratorio de datos (EDA)\n",
    "- Cuando necesitas gráficos estadísticos complejos (heatmaps, pair plots, etc.)\n",
    "- Para crear visualizaciones más atractivas con menos código que Matplotlib\n",
    "- Cuando trabajas principalmente con DataFrames de Pandas\n",
    "\n",
    "**Resumen de librerías de visualización:**\n",
    "- **Matplotlib**: Control total, gráficos estáticos, base para otras librerías\n",
    "- **Seaborn**: Visualizaciones estadísticas atractivas, fácil de usar con Pandas\n",
    "- **Plotly**: Gráficos interactivos, ideal para web y dashboards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a2666e",
   "metadata": {},
   "source": [
    "## **5. Principales comandos de scikit-learn (sklearn)**\n",
    "\n",
    "Scikit-learn es una librería de Python para aprendizaje automático y machine learning. A continuación se presentan los comandos más utilizados:\n",
    "\n",
    "### **Preprocesamiento de datos**\n",
    "- `StandardScaler()` - Estandarizar características (media=0, std=1) - Ejemplo en esta guía\n",
    "- `LabelEncoder()` - Codificar etiquetas categóricas a numéricas - Ejemplo en esta guía\n",
    "- `SimpleImputer()` - Rellenar valores faltantes\n",
    "- `train_test_split()` - Dividir datos en entrenamiento y prueba (generalmente 70% entrenamiento y 30% prueba)\n",
    "- `MinMaxScaler()` - Normalizar datos a rango [0,1]\n",
    "- `RobustScaler()` - Escalar usando mediana y rango intercuartil\n",
    "\n",
    "### **Modelos de regresión**\n",
    "- `LinearRegression()` - Regresión lineal\n",
    "- `Ridge()` - Regresión Ridge (regularización L2)\n",
    "- `Lasso()` - Regresión Lasso (regularización L1)\n",
    "- `ElasticNet()` - Regresión Elastic Net (L1 + L2)\n",
    "- `DecisionTreeRegressor()` - Árbol de decisión para regresión\n",
    "- `RandomForestRegressor()` - Bosque aleatorio para regresión\n",
    "- `GradientBoostingRegressor()` - Gradient Boosting para regresión\n",
    "\n",
    "### **Evaluación de modelos**\n",
    "- `mean_squared_error()` - Error cuadrático medio (MSE)\n",
    "- `r2_score()` - Coeficiente de determinación R²\n",
    "- `mean_absolute_error()` - Error absoluto medio (MAE)\n",
    "- `cross_val_score()` - Validación cruzada\n",
    "- `GridSearchCV()` - Búsqueda de hiperparámetros\n",
    "\n",
    "### **Métodos principales de modelos**\n",
    "- `.fit()` - Entrenar el modelo\n",
    "- `.predict()` - Realizar predicciones\n",
    "- `.score()` - Calcular score del modelo relacionado con las métricas de evaluación\n",
    "- `.get_params()` - Obtener parámetros del modelo (cuáles son las variables predictoras y su peso)\n",
    "- `.set_params()` - Establecer parámetros del modelo\n",
    "\n",
    "### **Transformadores**\n",
    "- `.fit()` - Ajustar el transformador a los datos\n",
    "- `.transform()` - Transformar los datos\n",
    "- `.fit_transform()` - Ajustar y transformar en un paso\n",
    "- `.inverse_transform()` - Transformación inversa\n",
    "\n",
    "### **Validación y selección de modelo**\n",
    "- `cross_val_score()` - Validación cruzada con scoring, es decir evalúa la métrica de error en cada evaluación por grupo de datos\n",
    "- `RandomizedSearchCV()` - Búsqueda aleatoria de hiperparámetros\n",
    "- `KFold()` - División en k-folds para validación cruzada (grupos de datos k-fold)\n",
    "\n",
    "### **Modelos de clasificación**\n",
    "\n",
    "Scikit-learn también ofrece modelos especializados para problemas de clasificación:\n",
    "\n",
    "- `LogisticRegression()` - Regresión logística (clasificación binaria y multiclase)\n",
    "- `DecisionTreeClassifier()` - Árbol de decisión para clasificación\n",
    "- `RandomForestClassifier()` - Bosque aleatorio para clasificación\n",
    "- `GradientBoostingClassifier()` - Gradient Boosting para clasificación\n",
    "- `SVC()` - Máquina de vectores de soporte (SVM) para clasificación\n",
    "- `KNeighborsClassifier()` - K vecinos más cercanos (KNN) para clasificación\n",
    "- `GaussianNB()` - Clasificador Bayesiano ingenuo Gaussiano\n",
    "\n",
    "### **Métricas de evaluación para clasificación**\n",
    "\n",
    "Las métricas de clasificación son diferentes a las de regresión:\n",
    "\n",
    "**Métricas principales:**\n",
    "- `accuracy_score()` - Exactitud (proporción de predicciones correctas)\n",
    "- `precision_score()` - Precisión (proporción de verdaderos positivos entre todos los positivos predichos)\n",
    "- `recall_score()` - Recall/Sensibilidad (proporción de positivos detectados correctamente)\n",
    "- `f1_score()` - F1-Score (media armónica de precisión y recall)\n",
    "- `confusion_matrix()` - Matriz de confusión\n",
    "- `classification_report()` - Reporte completo de métricas de clasificación\n",
    "\n",
    "**Diferencia clave con regresión:**\n",
    "- En **regresión** predecimos valores numéricos continuos (ej: precio de una casa)\n",
    "- En **clasificación** predecimos categorías/clases (ej: si un cliente comprará o no, 0 o 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c4e9c9",
   "metadata": {},
   "source": [
    "### **5.2 ¿Qué es StandardScaler?**\n",
    "\n",
    "**StandardScaler** es una herramienta de preprocesamiento de scikit-learn que estandariza las características (features) de tus datos.\n",
    "\n",
    "### ¿Qué hace?\n",
    "\n",
    "Transforma los datos para que tengan:\n",
    "- **Media = 0**\n",
    "- **Desviación estándar = 1**\n",
    "\n",
    "### Fórmula\n",
    "\n",
    "Para cada valor `x`, calcula:\n",
    "\n",
    "```\n",
    "x_estandarizado = (x - media) / desviación_estándar\n",
    "```\n",
    "\n",
    "### ¿Por qué es importante?\n",
    "\n",
    "1. **Escalas diferentes**: Si tus variables tienen rangos muy distintos (ej: edad 0-100, ingresos 0-1000000), algunos algoritmos (regresión, SVM, KNN, redes neuronales) pueden verse sesgados por las variables con valores más grandes.\n",
    "2. **Convergencia más rápida**: Ayuda a que algoritmos basados en gradientes converjan más rápido.\n",
    "3. **Comparación justa**: Pone todas las variables en la misma escala.\n",
    "\n",
    "### Ejemplo práctico:\n",
    "\n",
    "```python\n",
    "# Datos originales\n",
    "edad: [25, 30, 35, 40, 45]\n",
    "ingresos: [30000, 50000, 70000, 90000, 110000]\n",
    "\n",
    "# Después de StandardScaler\n",
    "edad: [-1.41, -0.71, 0, 0.71, 1.41]\n",
    "ingresos: [-1.41, -0.71, 0, 0.71, 1.41]\n",
    "```\n",
    "\n",
    "Ambas variables quedan en la misma escala, facilitando la comparación.\n",
    "\n",
    "### Uso típico:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Usa la misma media y std del entrenamiento\n",
    "```\n",
    "\n",
    "**Importante**: Ajusta (`fit`) solo con los datos de entrenamiento y luego transforma tanto entrenamiento como prueba con esos mismos parámetros para evitar data leakage.\n",
    "\n",
    "¿Quieres que revise cómo lo estás usando en tu código?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03839d",
   "metadata": {},
   "source": [
    "\n",
    "### **5.3 ¿Qué es LabelEncoder?**\n",
    "\n",
    "**Label Encoder** es una herramienta de `sklearn.preprocessing` que convierte etiquetas categóricas (texto) en números. Los algoritmos de Machine Learning suelen requerir datos numéricos, así que convierte categorías en enteros.\n",
    "\n",
    "### **¿Cómo funciona?**\n",
    "\n",
    "Asigna un número único a cada categoría única:\n",
    "\n",
    "**Ejemplo:**\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Datos originales (categóricos)\n",
    "colores = ['Rojo', 'Azul', 'Verde', 'Rojo', 'Azul']\n",
    "\n",
    "# Crear y aplicar LabelEncoder\n",
    "le = LabelEncoder()\n",
    "colores_numericos = le.fit_transform(colores)\n",
    "\n",
    "# Resultado:\n",
    "# ['Rojo', 'Azul', 'Verde', 'Rojo', 'Azul'] \n",
    "# se convierte en:\n",
    "# [2, 0, 1, 2, 0]\n",
    "```\n",
    "\n",
    "### **Características importantes:**\n",
    "\n",
    "1. Asignación automática: asigna números según el orden alfabético o de aparición\n",
    "2. Reversible: puedes volver a las categorías originales con `inverse_transform()`\n",
    "3. Útil para: variables categóricas nominales (sin orden inherente)\n",
    "\n",
    "### **Ejemplo práctico:**\n",
    "\n",
    "```python\n",
    "# Antes:\n",
    "Ciudad: ['Madrid', 'Barcelona', 'Valencia', 'Madrid']\n",
    "\n",
    "# Después de LabelEncoder:\n",
    "Ciudad: [1, 0, 2, 1]  # Barcelona=0, Madrid=1, Valencia=2\n",
    "```\n",
    "\n",
    "### **Limitación importante:**\n",
    "\n",
    "Label Encoder asigna números que pueden interpretarse como orden (0 < 1 < 2). Si las categorías no tienen orden, es mejor usar **One-Hot Encoding** para evitar que el modelo asuma relaciones numéricas entre categorías."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600d4d7",
   "metadata": {},
   "source": [
    "En scikit-learn, los modelos siguen un patrón consistente de uso. \n",
    "\n",
    "### **5.4 ¿Qué es scikit-learn?**\n",
    "\n",
    "scikit-learn (sklearn) es una biblioteca de Python que proporciona herramientas simples y eficientes para análisis predictivo de datos y machine learning.\n",
    "\n",
    "### Características principales:\n",
    "\n",
    "1. **API consistente**: Todos los modelos siguen el mismo patrón (fit, predict, score), en este orden\n",
    "2. **Preprocesamiento**: Herramientas para limpiar y preparar datos\n",
    "3. **Modelos**: Algoritmos de aprendizaje supervisado y no supervisado \n",
    "4. **Evaluación**: Métricas para medir el rendimiento de los modelos\n",
    "5. **Validación**: Herramientas para validar y seleccionar modelos\n",
    "\n",
    "### Patrón típico de uso en algoritmos de machine learning:\n",
    "\n",
    "```python\n",
    "# 1. Importar el modelo\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 2. Crear instancia del modelo\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# 3. Entrenar el modelo (fit)\n",
    "modelo.fit(X_entrenamiento, y_entrenamiento)\n",
    "\n",
    "# 4. Hacer predicciones (predict)\n",
    "predicciones = modelo.predict(X_prueba)\n",
    "\n",
    "# 5. Evaluar el modelo (score o métricas)\n",
    "r2 = modelo.score(X_prueba, y_prueba)\n",
    "```\n",
    "\n",
    "En el proyecto, sklearn se usa para entrenar modelos de regresión que predicen el consumo energético basándose en características de los paneles solares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9eda4c",
   "metadata": {},
   "source": [
    "### **5.5 `np.random.seed(42)` — Explicación**\n",
    "\n",
    "`np.random.seed(42)` fija la semilla para la generación de números aleatorios en NumPy. En análisis de datos, esto es fundamental para garantizar la reproducibilidad de los experimentos.\n",
    "\n",
    "### ¿Qué hace?\n",
    "- Fija el punto de partida del generador de números aleatorios.\n",
    "- Con la misma semilla, la secuencia de números “aleatorios” será la misma en cada ejecución.\n",
    "- Útil para reproducibilidad: los resultados son consistentes entre ejecuciones.\n",
    "\n",
    "### ¿Por qué el número 42?\n",
    "Es una convención (referencia a “La guía del autoestopista galáctico”). Puede ser cualquier entero; lo importante es usar el mismo valor para reproducir resultados. \n",
    "El uso del número 42 como parámetro `random_state` en el aprendizaje automático es una referencia humorística a la serie de ciencia ficción \"La guía del autoestopista galáctico\" de Douglas Adams. En la serie, el número 42 es conocido como la \"Respuesta a la Última Pregunta de la Vida, el Universo y Todo\", aunque la pregunta real es desconocida. \n",
    "Es una referencia caprichosa que ha sido adoptada por la comunidad de programación y ciencia de datos.\n",
    "\n",
    "**Importante:** No hay una razón técnica específica para usar el número 42 sobre cualquier otro valor. El propósito de establecer una semilla aleatoria (`random_state`) en aprendizaje automático es asegurar la reproducibilidad. Cuando usas la misma semilla aleatoria, obtendrás la misma secuencia de números aleatorios cada vez que ejecutes tu código. Esto es útil para depurar, compartir resultados y comparar diferentes modelos.\n",
    "\n",
    "La comunidad de ciencia de datos suele elegir números comúnmente reconocidos como el 42 como semilla aleatoria por tradición, pero cualquier valor entero funcionará igual de bien para lograr la reproducibilidad\n",
    "\n",
    "### Ejemplo práctico:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Sin seed: cada ejecución da números diferentes\n",
    "np.random.random(3)  # Puede dar: [0.374, 0.950, 0.732]\n",
    "np.random.random(3)  # Puede dar: [0.598, 0.156, 0.156]\n",
    "\n",
    "# Con seed: siempre da los mismos números\n",
    "np.random.seed(42)\n",
    "np.random.random(3)  # Siempre da: [0.37454012, 0.95071431, 0.73199394]\n",
    "\n",
    "np.random.seed(42)  # Resetear al inicio\n",
    "np.random.random(3)  # De nuevo: [0.37454012, 0.95071431, 0.73199394]\n",
    "```\n",
    "\n",
    "### ¿Cuándo usarlo?\n",
    "- En machine learning y análisis de datos: para que los experimentos sean reproducibles.\n",
    "- En pruebas: para garantizar resultados consistentes.\n",
    "- Al compartir código: para que otros obtengan los mismos resultados.\n",
    "\n",
    "**Resumen**: Fija el generador para obtener la misma secuencia en cada ejecución, útil para reproducibilidad. El `42` es arbitrario, aunque popular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6020007",
   "metadata": {},
   "source": [
    "### **5.6 Ejemplo simple con scikit-learn (Regresión)**\n",
    "\n",
    "A continuación se presenta un ejemplo básico y fácil de entender para operar con scikit-learn en problemas de regresión:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6c1cdaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de ejemplo (casas):\n",
      "   Tamaño_m2  Precio\n",
      "0        152  213311\n",
      "1        142  230819\n",
      "2         64  115188\n",
      "3        156  231568\n",
      "4        121  181269\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EJEMPLO SIMPLE CON SCIKIT-LEARN\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd  # Para crear el DataFrame\n",
    "import numpy as np  # Para crear arrays\n",
    "from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba\n",
    "from sklearn.linear_model import LinearRegression  # Para crear el modelo de regresión lineal\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # Para evaluar el modelo\n",
    "from sklearn.preprocessing import StandardScaler  # Para estandarizar las características\n",
    "\n",
    "# 1. Crear datos de ejemplo. Simulamos datos de casas: tamaño (m²) y precio usando NumPy\n",
    "np.random.seed(42)  # Para reproducibilidad, seed es una semilla que genera números aleatorios iguales para cada ejecución\n",
    "tamaño = np.random.randint(50, 200, 20)  # Tamaño en m²\n",
    "precio = tamaño * 1500 + np.random.randint(-20000, 20000, 20)  # Precio relacionado con tamaño\n",
    "\n",
    "# 2. Crear DataFrame usando Pandas\n",
    "df_casas = pd.DataFrame({\n",
    "    'Tamaño_m2': tamaño,\n",
    "    'Precio': precio\n",
    "})\n",
    "\n",
    "print(\"Datos de ejemplo (casas):\")\n",
    "print(df_casas.head())\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "bae7cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características (X):\n",
      "   Tamaño_m2\n",
      "0        152\n",
      "1        142\n",
      "2         64\n",
      "3        156\n",
      "4        121\n",
      "\n",
      "Variable objetivo (y):\n",
      "0    213311\n",
      "1    230819\n",
      "2    115188\n",
      "3    231568\n",
      "4    181269\n",
      "Name: Precio, dtype: int32\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3. Separar características (X) y variable objetivo (y)\n",
    "X = df_casas[['Tamaño_m2']]  # Característica: tamaño de la casa\n",
    "y = df_casas['Precio']  # Variable objetivo: precio de la casa\n",
    "\n",
    "print(\"Características (X):\")\n",
    "print(X.head())\n",
    "print(\"\\nVariable objetivo (y):\")\n",
    "print(y.head())\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "456eb47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento: 14 muestras\n",
      "Datos de prueba: 6 muestras\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3,  # 30% para prueba, 70% para entrenamiento\n",
    "    random_state=42  # Para reproducibilidad\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Datos de prueba: {X_test.shape[0]} muestras\")\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "08e90972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado exitosamente!\n",
      "Coeficiente (pendiente): 1520.32\n",
      "Intercepto: -7008.01\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. Crear y entrenar el modelo de regresión lineal\n",
    "modelo = LinearRegression()  # Crear instancia del modelo\n",
    "modelo.fit(X_train, y_train)  # Entrenar el modelo con datos de entrenamiento\n",
    "\n",
    "print(\"Modelo entrenado exitosamente!\")\n",
    "print(f\"Coeficiente (pendiente): {modelo.coef_[0]:.2f}\")  # Imprime el coeficiente del modelo\n",
    "print(f\"Intercepto: {modelo.intercept_:.2f}\")  # Imprime el intercepto del modelo\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b3f582c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones vs Valores reales:\n",
      "   Tamaño_m2  Precio_Real  Precio_Predicho\n",
      "0        152       213311    224080.733746\n",
      "1        137       217051    201275.923399\n",
      "2        102       134899    148064.699256\n",
      "3        142       230819    208877.526848\n",
      "4        124       191658    181511.754431\n",
      "5         70       113693     99414.437182\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. Hacer predicciones\n",
    "y_pred = modelo.predict(X_test)  # Predecir precios para datos de prueba\n",
    "\n",
    "print(\"Predicciones vs Valores reales:\")\n",
    "resultados = pd.DataFrame({\n",
    "    'Tamaño_m2': X_test['Tamaño_m2'].values,\n",
    "    'Precio_Real': y_test.values,\n",
    "    'Precio_Predicho': y_pred\n",
    "})\n",
    "print(resultados.head(10))\n",
    "print(\"\\n\" + \"-\" * 50)  # imprime la linea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "01c78e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de evaluación del modelo:\n",
      "Error Cuadrático Medio (MSE): 221071290.50\n",
      "Coeficiente de Determinación (R²): 0.8852\n",
      "Error Absoluto Medio (MAE): 14346.13\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluar el modelo con métricas\n",
    "mse = mean_squared_error(y_test, y_pred)  # Error cuadrático medio\n",
    "r2 = r2_score(y_test, y_pred)  # Coeficiente de determinación R²\n",
    "mae = mean_absolute_error(y_test, y_pred)  # Error absoluto medio\n",
    "\n",
    "print(\"Métricas de evaluación del modelo:\")\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")  # Imprime el error cuadrático medio\n",
    "print(f\"Coeficiente de Determinación (R²): {r2:.4f}\")  # Imprime el R² (1.0 es perfecto)\n",
    "print(f\"Error Absoluto Medio (MAE): {mae:.2f}\")  # Imprime el error absoluto medio\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4e7f51fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para una casa de 100 m²:\n",
      "Precio predicho: $145,024.06\n"
     ]
    }
   ],
   "source": [
    "# 8. Hacer una predicción para una nueva casa\n",
    "nueva_casa = pd.DataFrame({'Tamaño_m2': [100]})  # Casa de 100 m²\n",
    "precio_predicho = modelo.predict(nueva_casa)  # Predecir el precio\n",
    "\n",
    "print(f\"Para una casa de {nueva_casa['Tamaño_m2'][0]} m²:\")\n",
    "print(f\"Precio predicho: ${precio_predicho[0]:,.2f}\")  # Imprime el precio predicho para la nueva casa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6626134",
   "metadata": {},
   "source": [
    "### **3.7 Ejemplo simple con scikit-learn - Clasificación con Random Forest**\n",
    "\n",
    "A continuación se presenta un ejemplo básico y fácil de entender para operar con scikit-learn en clasificación usando Random Forest:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a888acb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de ejemplo (clientes):\n",
      "   Edad  Ingresos  Compro\n",
      "0    56     78053       1\n",
      "1    69     41959       0\n",
      "2    46     25530       0\n",
      "3    32     23748       0\n",
      "4    60     33545       0\n",
      "5    25     86199       1\n",
      "6    38     54766       1\n",
      "7    56     93530       1\n",
      "8    36     81087       1\n",
      "9    40     88840       1\n",
      "\n",
      "Distribución de compras:\n",
      "Compro\n",
      "0    114\n",
      "1     86\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EJEMPLO SIMPLE CON SCIKIT-LEARN - CLASIFICACIÓN CON RANDOM FOREST\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Crear datos de ejemplo. Simulamos datos de clientes: edad, ingresos y si compró un producto\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "n_samples = 200\n",
    "\n",
    "# Generar datos sintéticos\n",
    "edad = np.random.randint(18, 70, n_samples)  # Edad entre 18 y 70 años\n",
    "ingresos = np.random.randint(20000, 100000, n_samples)  # Ingresos entre 20k y 100k\n",
    "\n",
    "# Crear variable objetivo (si compró o no) basada en edad e ingresos\n",
    "# Lógica: mayores ingresos y edad entre 30-50 años tienen mayor probabilidad de comprar\n",
    "probabilidad_compra = (ingresos / 50000) + (edad >= 30) * (edad <= 50) * 0.5\n",
    "compra = (probabilidad_compra + np.random.normal(0, 0.3, n_samples) > 1.5).astype(int)\n",
    "\n",
    "# 2. Crear DataFrame usando Pandas\n",
    "df_clientes = pd.DataFrame({\n",
    "    'Edad': edad,\n",
    "    'Ingresos': ingresos,\n",
    "    'Compro': compra  # 1 = Sí compró, 0 = No compró\n",
    "})\n",
    "\n",
    "print(\"Datos de ejemplo (clientes):\")\n",
    "print(df_clientes.head(10))\n",
    "print(f\"\\nDistribución de compras:\")\n",
    "print(df_clientes['Compro'].value_counts())\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "de8aa6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características (X):\n",
      "   Edad  Ingresos\n",
      "0    56     78053\n",
      "1    69     41959\n",
      "2    46     25530\n",
      "3    32     23748\n",
      "4    60     33545\n",
      "\n",
      "Variable objetivo (y):\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Compro, dtype: int64\n",
      "\n",
      "Forma de X: (200, 2)\n",
      "Forma de y: (200,)\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3. Separar características (X) y variable objetivo (y)\n",
    "X = df_clientes[['Edad', 'Ingresos']]  # Características: edad e ingresos\n",
    "y = df_clientes['Compro']  # Variable objetivo: si compró (0 o 1)\n",
    "\n",
    "print(\"Características (X):\")\n",
    "print(X.head())\n",
    "print(\"\\nVariable objetivo (y):\")\n",
    "print(y.head())\n",
    "print(f\"\\nForma de X: {X.shape}\")  # (200, 2) - 200 muestras, 2 características\n",
    "print(f\"Forma de y: {y.shape}\")    # (200,) - 200 muestras\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5841e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento: 140 muestras\n",
      "Datos de prueba: 60 muestras\n",
      "\n",
      "Distribución en entrenamiento:\n",
      "Compro\n",
      "0    80\n",
      "1    60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución en prueba:\n",
      "Compro\n",
      "0    34\n",
      "1    26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3,  # 30% para prueba, 70% para entrenamiento\n",
    "    random_state=42,  # Para reproducibilidad\n",
    "    stratify=y  # Mantiene la proporción de clases en train y test\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Datos de prueba: {X_test.shape[0]} muestras\")\n",
    "print(f\"\\nDistribución en entrenamiento:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nDistribución en prueba:\")\n",
    "print(y_test.value_counts())\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7a2985d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Random Forest entrenado exitosamente!\n",
      "Número de árboles: 100\n",
      "Importancia de características:\n",
      "  Edad: 0.2599\n",
      "  Ingresos: 0.7401\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. Crear y entrenar el modelo Random Forest\n",
    "# Random Forest combina múltiples árboles de decisión para mejorar la precisión\n",
    "modelo = RandomForestClassifier(\n",
    "    n_estimators=100,  # Número de árboles en el bosque\n",
    "    random_state=42,   # Para reproducibilidad\n",
    "    max_depth=5        # Profundidad máxima de cada árbol\n",
    ")\n",
    "\n",
    "modelo.fit(X_train, y_train)  # Entrenar el modelo con datos de entrenamiento\n",
    "\n",
    "print(\"Modelo Random Forest entrenado exitosamente!\")\n",
    "print(f\"Número de árboles: {modelo.n_estimators}\")\n",
    "print(f\"Importancia de características:\")\n",
    "for i, feature in enumerate(X.columns):\n",
    "    print(f\"  {feature}: {modelo.feature_importances_[i]:.4f}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "da5b9278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones vs Valores reales:\n",
      "   Edad  Ingresos  Compro_Real  Compro_Predicho  Probabilidad_Comprar\n",
      "0    32     58467            1                0              0.314456\n",
      "1    62     98069            1                1              0.883942\n",
      "2    24     30647            0                0              0.034596\n",
      "3    35     62642            1                1              0.509683\n",
      "4    19     49855            0                0              0.037645\n",
      "5    36     81087            1                1              0.854093\n",
      "6    28     39830            0                0              0.065001\n",
      "7    41     93744            1                1              0.980227\n",
      "8    23     81434            1                1              0.576695\n",
      "9    56     23051            0                0              0.029849\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. Hacer predicciones\n",
    "y_pred = modelo.predict(X_test)  # Predecir clases (0 o 1) para datos de prueba\n",
    "y_pred_proba = modelo.predict_proba(X_test)  # Predecir probabilidades\n",
    "\n",
    "print(\"Predicciones vs Valores reales:\")\n",
    "resultados = pd.DataFrame({\n",
    "    'Edad': X_test['Edad'].values,\n",
    "    'Ingresos': X_test['Ingresos'].values,\n",
    "    'Compro_Real': y_test.values,\n",
    "    'Compro_Predicho': y_pred,\n",
    "    'Probabilidad_Comprar': y_pred_proba[:, 1]  # Probabilidad de comprar (clase 1)\n",
    "})\n",
    "print(resultados.head(10))\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fb913fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de evaluación del modelo:\n",
      "Exactitud (Accuracy): 0.8000 (80.00%)\n",
      "Precisión (Precision): 0.8182\n",
      "Recall/Sensibilidad: 0.6923\n",
      "F1-Score: 0.7500\n",
      "\n",
      "Matriz de confusión:\n",
      "                    Predicho\n",
      "                 No(0)    Sí(1)\n",
      "Real    No(0)     30       4\n",
      "        Sí(1)      8      18\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluar el modelo con métricas de clasificación\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Exactitud (proporción de predicciones correctas)\n",
    "precision = precision_score(y_test, y_pred)  # Precisión (verdaderos positivos / todos los positivos predichos)\n",
    "recall = recall_score(y_test, y_pred)  # Recall/Sensibilidad (verdaderos positivos / todos los positivos reales)\n",
    "f1 = f1_score(y_test, y_pred)  # F1-Score (media armónica de precisión y recall)\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)  # Matriz de confusión\n",
    "\n",
    "print(\"Métricas de evaluación del modelo:\")\n",
    "print(f\"Exactitud (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precisión (Precision): {precision:.4f}\")\n",
    "print(f\"Recall/Sensibilidad: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(\"                    Predicho\")\n",
    "print(\"                 No(0)    Sí(1)\")\n",
    "print(f\"Real    No(0)    {matriz_confusion[0][0]:3d}     {matriz_confusion[0][1]:3d}\")\n",
    "print(f\"        Sí(1)    {matriz_confusion[1][0]:3d}     {matriz_confusion[1][1]:3d}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "25613e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte completo de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Compró       0.79      0.88      0.83        34\n",
      "      Compró       0.82      0.69      0.75        26\n",
      "\n",
      "    accuracy                           0.80        60\n",
      "   macro avg       0.80      0.79      0.79        60\n",
      "weighted avg       0.80      0.80      0.80        60\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 8. Reporte completo de clasificación\n",
    "print(\"Reporte completo de clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Compró', 'Compró']))\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "db35b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para un cliente de 35 años con ingresos de $60,000:\n",
      "Predicción: Sí comprará\n",
      "Probabilidad de comprar: 52.31%\n",
      "Probabilidad de no comprar: 47.69%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 9. Hacer predicción para un nuevo cliente\n",
    "nuevo_cliente = pd.DataFrame({\n",
    "    'Edad': [35],\n",
    "    'Ingresos': [60000]\n",
    "})\n",
    "\n",
    "# Predecir clase y probabilidad\n",
    "prediccion = modelo.predict(nuevo_cliente)[0]\n",
    "probabilidad = modelo.predict_proba(nuevo_cliente)[0]\n",
    "\n",
    "print(f\"Para un cliente de {nuevo_cliente['Edad'][0]} años con ingresos de ${nuevo_cliente['Ingresos'][0]:,}:\")\n",
    "print(f\"Predicción: {'Sí comprará' if prediccion == 1 else 'No comprará'}\")\n",
    "print(f\"Probabilidad de comprar: {probabilidad[1]*100:.2f}%\")\n",
    "print(f\"Probabilidad de no comprar: {probabilidad[0]*100:.2f}%\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "eabef4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score del modelo:\n",
      "Exactitud en entrenamiento: 0.9286 (92.86%)\n",
      "Exactitud en prueba: 0.8000 (80.00%)\n",
      "\n",
      "⚠ Atención: Diferencia alta entre entrenamiento y prueba (0.1286)\n",
      "   El modelo podría estar sobreajustado.\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 10. Comparar con el score del modelo (método directo)\n",
    "score_train = modelo.score(X_train, y_train)  # Exactitud en entrenamiento\n",
    "score_test = modelo.score(X_test, y_test)  # Exactitud en prueba\n",
    "\n",
    "print(\"Score del modelo:\")\n",
    "print(f\"Exactitud en entrenamiento: {score_train:.4f} ({score_train*100:.2f}%)\")\n",
    "print(f\"Exactitud en prueba: {score_test:.4f} ({score_test*100:.2f}%)\")\n",
    "\n",
    "# Si hay mucha diferencia entre train y test, el modelo podría estar sobreajustado\n",
    "diferencia = abs(score_train - score_test)\n",
    "if diferencia > 0.1:\n",
    "    print(f\"\\n⚠ Atención: Diferencia alta entre entrenamiento y prueba ({diferencia:.4f})\")\n",
    "    print(\"   El modelo podría estar sobreajustado.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Diferencia aceptable entre entrenamiento y prueba ({diferencia:.4f})\")\n",
    "print(\"\\n\" + \"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae18e58",
   "metadata": {},
   "source": [
    "## **4. Principales comandos de openpyxl**\n",
    "\n",
    "Openpyxl es una librería de Python para leer y escribir archivos Excel (.xlsx, .xlsm). A continuación se presentan los comandos más utilizados:\n",
    "\n",
    "### **Abrir y cerrar archivos Excel**\n",
    "- `load_workbook()` - Cargar un archivo Excel existente\n",
    "- `Workbook()` - Crear un nuevo archivo Excel en blanco\n",
    "- `.save()` - Guardar el archivo Excel\n",
    "- `.close()` - Cerrar el archivo Excel\n",
    "\n",
    "### **Navegación entre hojas**\n",
    "- `.sheetnames` - Obtener lista de nombres de hojas\n",
    "- `wb['NombreHoja']` - Seleccionar una hoja por nombre\n",
    "- `wb.active` - Acceder a la hoja activa\n",
    "- `wb.worksheets` - Lista de todas las hojas del libro\n",
    "\n",
    "### **Lectura de datos**\n",
    "- `.cell(fila, columna)` - Acceder a una celda específica (fila, columna)\n",
    "- `.cell(fila, columna).value` - Obtener el valor de una celda\n",
    "- `.max_row` - Obtener el número de la última fila con datos\n",
    "- `.max_column` - Obtener el número de la última columna con datos\n",
    "- `.iter_rows()` - Iterar sobre filas\n",
    "- `.iter_cols()` - Iterar sobre columnas\n",
    "- `[fila][columna]` - Acceso directo por índice (ej: `ws['A1']`)\n",
    "\n",
    "### **Escritura de datos**\n",
    "- `.cell(fila, columna, valor)` - Escribir valor en una celda\n",
    "- `ws['A1'] = valor` - Asignar valor directamente a celda\n",
    "- `.append()` - Agregar una fila al final de la hoja\n",
    "- `.merge_cells()` - Combinar celdas\n",
    "- `.unmerge_cells()` - Descombinar celdas\n",
    "\n",
    "### **Formato de celdas**\n",
    "- `.font` - Configurar fuente (tamaño, negrita, color)\n",
    "- `.fill` - Configurar relleno de celda\n",
    "- `.border` - Configurar bordes\n",
    "- `.alignment` - Configurar alineación (centrado, izquierda, derecha)\n",
    "- `.number_format` - Configurar formato de números\n",
    "\n",
    "### **Manipulación de hojas**\n",
    "- `.create_sheet()` - Crear una nueva hoja\n",
    "- `.remove()` - Eliminar una hoja\n",
    "- `.copy_worksheet()` - Copiar una hoja\n",
    "- `.title` - Cambiar el nombre de la hoja\n",
    "\n",
    "### **Filtros y validación**\n",
    "- `.auto_filter` - Aplicar filtros automáticos\n",
    "- `.freeze_panes` - Congelar paneles (filas/columnas)\n",
    "- `.data_validation` - Agregar validación de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf0e1f",
   "metadata": {},
   "source": [
    "### **4.2 ¿Qué es openpyxl?**\n",
    "\n",
    "**openpyxl** es una biblioteca de Python para leer y escribir archivos Excel (.xlsx, .xlsm).\n",
    "\n",
    "### Características principales:\n",
    "\n",
    "1. **Lectura y escritura**: Permite leer datos de archivos Excel existentes y crear nuevos archivos Excel\n",
    "2. **Formato completo**: Soporta lectura y escritura de formatos, estilos, fórmulas, gráficos, etc.\n",
    "3. **Manipulación de hojas**: Permite crear, eliminar, copiar y modificar hojas de cálculo\n",
    "4. **Compatibilidad**: Funciona con archivos Excel modernos (.xlsx, .xlsm), no con formatos antiguos (.xls)\n",
    "\n",
    "### Conceptos clave:\n",
    "\n",
    "- **Workbook (`wb`)**: Representa todo el archivo Excel (libro de trabajo)\n",
    "- **Worksheet (`ws`)**: Representa una hoja individual dentro del libro\n",
    "- **Cell**: Representa una celda individual con su valor, formato, etc.\n",
    "- **Notación**: Las filas se numeran desde 1, las columnas pueden ser números (1, 2, 3) o letras ('A', 'B', 'C')\n",
    "\n",
    "### Ejemplo típico de uso:\n",
    "\n",
    "```python\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Cargar un archivo Excel existente\n",
    "wb = load_workbook('archivo.xlsx')\n",
    "\n",
    "# Seleccionar una hoja\n",
    "ws = wb['Hoja1']  # o wb.active para la hoja activa\n",
    "\n",
    "# Leer el valor de una celda\n",
    "valor = ws['A1'].value  # o ws.cell(1, 1).value\n",
    "\n",
    "# Escribir en una celda\n",
    "ws['A1'] = 'Nuevo valor'\n",
    "\n",
    "# Guardar el archivo\n",
    "wb.save('archivo.xlsx')\n",
    "wb.close()\n",
    "```\n",
    "\n",
    "En el proyecto, openpyxl se usa cuando necesitas leer datos directamente desde archivos Excel con más control que `pd.read_excel()`, o cuando necesitas crear o modificar archivos Excel con formato específico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed9de7",
   "metadata": {},
   "source": [
    "### **4.3 Ejemplo simple con openpyxl**\n",
    "\n",
    "A continuación se presenta un ejemplo básico y fácil de entender para operar con openpyxl:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4730502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel creado exitosamente\n",
      "Nombre de la hoja: Datos\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EJEMPLO SIMPLE CON OPENPYXL\n",
    "# ============================================\n",
    "\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.styles import Font, Alignment, PatternFill\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# 1. Crear un nuevo archivo Excel\n",
    "wb = Workbook()  # Crea un nuevo libro de trabajo\n",
    "ws = wb.active  # Selecciona la hoja activa (por defecto se llama \"Sheet\")\n",
    "ws.title = \"Datos\"  # Cambia el nombre de la hoja a \"Datos\"\n",
    "\n",
    "print(\"Archivo Excel creado exitosamente\")\n",
    "print(f\"Nombre de la hoja: {ws.title}\")\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2ca7e9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos escritos en el archivo Excel\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. Escribir datos en celdas\n",
    "ws['A1'] = 'Nombre'  # Escribe en la celda A1\n",
    "ws['B1'] = 'Edad'  # Escribe en la celda B1\n",
    "ws['C1'] = 'Ciudad'  # Escribe en la celda C1\n",
    "\n",
    "# Escribir datos usando el método cell()\n",
    "ws.cell(2, 1, 'Ana')  # Fila 2, Columna 1 (A2)\n",
    "ws.cell(2, 2, 25)  # Fila 2, Columna 2 (B2)\n",
    "ws.cell(2, 3, 'Madrid')  # Fila 2, Columna 3 (C2)\n",
    "\n",
    "# Agregar más filas usando append()\n",
    "ws.append(['Luis', 30, 'Barcelona'])  # Agrega una fila al final\n",
    "ws.append(['María', 28, 'Valencia'])\n",
    "ws.append(['Carlos', 35, 'Madrid'])\n",
    "\n",
    "print(\"Datos escritos en el archivo Excel\")\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "00f65787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lectura de datos del archivo Excel:\n",
      "Celda A1: Nombre\n",
      "Celda B2: 25\n",
      "\n",
      "Última fila con datos: 5\n",
      "Última columna con datos: 3\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3. Leer datos de celdas\n",
    "print(\"Lectura de datos del archivo Excel:\")\n",
    "print(f\"Celda A1: {ws['A1'].value}\")  # Lee el valor de la celda A1\n",
    "print(f\"Celda B2: {ws.cell(2, 2).value}\")  # Lee el valor de la fila 2, columna 2 (B2)\n",
    "\n",
    "print(f\"\\nÚltima fila con datos: {ws.max_row}\")  # Imprime el número de la última fila con datos\n",
    "print(f\"Última columna con datos: {ws.max_column}\")  # Imprime el número de la última columna con datos\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c5575471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato aplicado a los encabezados\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. Aplicar formato a las celdas (encabezados)\n",
    "header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")  # Color azul de fondo\n",
    "header_font = Font(bold=True, color=\"FFFFFF\", size=12)  # Texto en negrita, color blanco, tamaño 12\n",
    "header_alignment = Alignment(horizontal=\"center\", vertical=\"center\")  # Texto centrado\n",
    "\n",
    "# Aplicar formato a la primera fila (encabezados)\n",
    "for cell in ws[1]:  # Itera sobre todas las celdas de la fila 1\n",
    "    cell.fill = header_fill  # Aplica el color de fondo\n",
    "    cell.font = header_font  # Aplica la fuente\n",
    "    cell.alignment = header_alignment  # Aplica la alineación\n",
    "\n",
    "print(\"Formato aplicado a los encabezados\")\n",
    "print(\"\\n\" + \"-\" * 50)  # imprime la linea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c7eb61bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel guardado como 'ejemplo_openpyxl.xlsx'\n",
      "Archivo Excel cerrado\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. Guardar el archivo Excel\n",
    "wb.save('ejemplo_openpyxl.xlsx')  # Guarda el archivo Excel con el nombre especificado\n",
    "print(\"Archivo Excel guardado como 'ejemplo_openpyxl.xlsx'\")\n",
    "\n",
    "# Cerrar el archivo (opcional, se cierra automáticamente al terminar)\n",
    "wb.close()\n",
    "print(\"Archivo Excel cerrado\")\n",
    "print(\"\\n\" + \"-\" * 50)  # Imprime la línea punteada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f0da53c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lectura de archivo Excel existente:\n",
      "Nombre de la hoja: Datos\n",
      "Número de filas: 5\n",
      "Número de columnas: 3\n",
      "\n",
      "Datos de todas las filas:\n",
      "('Nombre', 'Edad', 'Ciudad')\n",
      "('Ana', 25, 'Madrid')\n",
      "('Luis', 30, 'Barcelona')\n",
      "('María', 28, 'Valencia')\n",
      "('Carlos', 35, 'Madrid')\n"
     ]
    }
   ],
   "source": [
    "# 6. Leer un archivo Excel existente\n",
    "try:\n",
    "    # Cargar el archivo que acabamos de crear\n",
    "    wb_lectura = load_workbook('ejemplo_openpyxl.xlsx')  # Carga el archivo Excel existente\n",
    "    ws_lectura = wb_lectura.active  # Selecciona la hoja activa\n",
    "    \n",
    "    print(\"Lectura de archivo Excel existente:\")\n",
    "    print(f\"Nombre de la hoja: {ws_lectura.title}\")  # Imprime el nombre de la hoja\n",
    "    print(f\"Número de filas: {ws_lectura.max_row}\")  # Imprime el número de filas\n",
    "    print(f\"Número de columnas: {ws_lectura.max_column}\")  # Imprime el número de columnas\n",
    "    \n",
    "    print(\"\\nDatos de todas las filas:\")\n",
    "    # Iterar sobre todas las filas con datos\n",
    "    for row in ws_lectura.iter_rows(values_only=True):  # Itera sobre filas, devuelve solo valores\n",
    "        print(row)  # Imprime cada fila\n",
    "    \n",
    "    wb_lectura.close()  # Cierra el archivo\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo no existe aún. Ejecuta primero las celdas anteriores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7c7da",
   "metadata": {},
   "source": [
    "## **5. ¿Qué son los modelos PKL (Pickle) y por qué se guardan?**\n",
    "\n",
    "Los archivos `.pkl` (Pickle) son archivos binarios de Python que permiten **serializar** (convertir a bytes) y **deserializar** (recuperar) objetos de Python para guardarlos en disco y reutilizarlos después. Los bytes son representaciones binarias compuestas de ceros (0) y unos (1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3406b",
   "metadata": {},
   "source": [
    "### **5.1 ¿Qué es Pickle?**\n",
    "\n",
    "**Pickle** es un módulo de Python que permite guardar objetos de Python (como modelos de machine learning entrenados) en archivos binarios (`.pkl`). Esto es útil porque:\n",
    "\n",
    "1. **Preservación del estado**: Guarda el modelo completo con todos sus parámetros entrenados\n",
    "2. **Reutilización**: Permite usar el modelo sin tener que entrenarlo de nuevo\n",
    "3. **Persistencia**: El modelo se guarda permanentemente en disco\n",
    "4. **Eficiencia**: Evita re-entrenar modelos que pueden tardar horas o días\n",
    "\n",
    "### **¿Por qué se guardan los modelos?**\n",
    "\n",
    "Después de entrenar un modelo de machine learning, normalmente:\n",
    "- El entrenamiento puede tomar mucho tiempo (minutos, horas o días)\n",
    "- El modelo contiene parámetros aprendidos (pesos, coeficientes, árboles, etc.)\n",
    "- Necesitas usar el modelo en el futuro sin volver a entrenarlo\n",
    "- Quieres compartir el modelo con otros usuarios o sistemas\n",
    "\n",
    "**Sin guardar el modelo**: Tendrías que entrenarlo cada vez que lo necesites (muy ineficiente)\n",
    "\n",
    "**Con el modelo guardado**: Solo cargas el archivo `.pkl` y haces predicciones inmediatamente. La idea es que el despliegue de este modelo se realice en Excel, lo cual se aprenderá a hacer en este curso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff942ab7",
   "metadata": {},
   "source": [
    "### **5.2 ¿Qué contiene un modelo PKL?**\n",
    "\n",
    "Un archivo `.pkl` puede contener:\n",
    "\n",
    "1. **El modelo entrenado**: Con todos sus parámetros y pesos aprendidos\n",
    "2. **Objetos auxiliares**: \n",
    "   - `StandardScaler` (escalador de datos)\n",
    "   - `LabelEncoder` (codificador de etiquetas)\n",
    "   - `SimpleImputer` (para valores faltantes)\n",
    "   - Lista de nombres de características (features)\n",
    "   - Metadatos del modelo\n",
    "\n",
    "3. **Información adicional**:\n",
    "   - Métricas de evaluación (R², RMSE, MAE)\n",
    "   - Parámetros del modelo\n",
    "   - Fecha de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15afab6",
   "metadata": {},
   "source": [
    "### **5.3 Alternativas a Pickle**\n",
    "\n",
    "- **Joblib**: Similar a Pickle pero más eficiente para arrays grandes de NumPy (recomendado para scikit-learn)\n",
    "- **HDF5**: Para modelos grandes y datasets\n",
    "- **ONNX**: Formato estándar para intercambiar modelos entre frameworks\n",
    "- **TensorFlow SavedModel / PyTorch**: Formatos específicos de estos frameworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a2d80",
   "metadata": {},
   "source": [
    "### **5.4 ¿Qué es un Framework?**\n",
    "\n",
    "Un **framework** (marco de trabajo) es un conjunto de herramientas, bibliotecas y reglas que facilita el desarrollo de software. Proporciona una estructura base y funciones comunes para que te enfoques en la lógica de tu aplicación.\n",
    "\n",
    "### Analogía simple\n",
    "Si construir una aplicación fuera construir una casa:\n",
    "- **Sin framework**: Compilas cada herramienta desde cero (martillo, tornillos, diseño).\n",
    "- **Con framework**: Ya tienes herramientas y un plano base; te enfocas en los detalles.\n",
    "\n",
    "### Características principales\n",
    "\n",
    "1. **Estructura predefinida**: Define cómo organizar tu código.\n",
    "2. **Funcionalidades comunes**: Incluye funciones listas (autenticación, manejo de datos, etc.).\n",
    "3. **Patrones de diseño**: Usa buenas prácticas ya probadas.\n",
    "4. **Ahorro de tiempo**: Evita escribir código repetitivo.\n",
    "\n",
    "### Ejemplos comunes de Framework\n",
    "\n",
    "- **Para Machine Learning**: TensorFlow, PyTorch, scikit-learn\n",
    "- **Para web**: Django (Python), Flask (Python), React (JavaScript)\n",
    "- **Para datos**: pandas, NumPy\n",
    "\n",
    "### Framework vs. Librería\n",
    "\n",
    "- **Librería**: Herramientas que eliges usar cuando quieres (ej: `pandas`).\n",
    "- **Framework**: Estructura que sigue tu código; tu código \"llena\" el framework. Por ejemplo, en machine learning con scikit-learn la estructura que sigue el código es: fit, predict y finalmente score.\n",
    "\n",
    "En resumen: un framework da estructura y herramientas para desarrollar más rápido y con mejores prácticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d0e14",
   "metadata": {},
   "source": [
    "### **5.5 Ejemplo práctico: Guardar y cargar modelos PKL**\n",
    "\n",
    "A continuación se presenta un ejemplo completo y fácil de entender para operar con modelos PKL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d27d81a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EJEMPLO: GUARDAR Y CARGAR MODELOS PKL\n",
      "======================================================================\n",
      "\n",
      "1. Datos de ejemplo creados:\n",
      "   Tamaño_m2  Precio\n",
      "0        152  213311\n",
      "1        142  230819\n",
      "2         64  115188\n",
      "3        156  231568\n",
      "4        121  181269\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EJEMPLO COMPLETO: GUARDAR Y CARGAR MODELOS PKL\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pickle  # Librería para guardar y cargar modelos PKL\n",
    "import joblib  # Alternativa más eficiente para modelos de scikit-learn\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EJEMPLO: GUARDAR Y CARGAR MODELOS PKL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Crear datos de ejemplo\n",
    "np.random.seed(42)\n",
    "tamaño = np.random.randint(50, 200, 20)\n",
    "precio = tamaño * 1500 + np.random.randint(-20000, 20000, 20)\n",
    "\n",
    "df_casas = pd.DataFrame({\n",
    "    'Tamaño_m2': tamaño,\n",
    "    'Precio': precio\n",
    "})\n",
    "\n",
    "print(\"\\n1. Datos de ejemplo creados:\")\n",
    "print(df_casas.head())\n",
    "print(\"\\n\" + \"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e6f1a99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Modelo entrenado exitosamente!\n",
      "   R² Score: 0.8852\n",
      "   RMSE: 14868.47\n",
      "   Coeficiente: 65218.56\n",
      "   Intercepto: 206379.86\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. Preparar datos y entrenar modelo\n",
    "X = df_casas[['Tamaño_m2']]\n",
    "y = df_casas['Precio']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear y entrenar escalador\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluar modelo\n",
    "y_pred = modelo.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"2. Modelo entrenado exitosamente!\")\n",
    "print(f\"   R² Score: {r2:.4f}\")\n",
    "print(f\"   RMSE: {rmse:.2f}\")\n",
    "print(f\"   Coeficiente: {modelo.coef_[0]:.2f}\")\n",
    "print(f\"   Intercepto: {modelo.intercept_:.2f}\")\n",
    "print(\"\\n\" + \"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5ef5eff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. GUARDANDO MODELO CON PICKLE:\n",
      "   ------------------------------------------------------------------\n",
      "   ✓ Modelo guardado: modelo_casas.pkl\n",
      "   ✓ Escalador guardado: scaler_casas.pkl\n",
      "   ✓ Modelo completo guardado: modelo_completo_casas.pkl\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3. GUARDAR MODELO CON PICKLE (método estándar)\n",
    "print(\"3. GUARDANDO MODELO CON PICKLE:\")\n",
    "print(\"   \" + \"-\" * 66)\n",
    "\n",
    "# Guardar solo el modelo\n",
    "with open('modelo_casas.pkl', 'wb') as f:  # 'wb' = write binary (escribir binario)\n",
    "    pickle.dump(modelo, f)\n",
    "print(\"   ✓ Modelo guardado: modelo_casas.pkl\")\n",
    "\n",
    "# Guardar el escalador (importante para futuras predicciones), ya que los datos de evaluación también deben estar escalados\n",
    "with open('scaler_casas.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"   ✓ Escalador guardado: scaler_casas.pkl\")\n",
    "\n",
    "# Guardar TODO junto (modelo + escalador + información)\n",
    "modelo_completo = {\n",
    "    'modelo': modelo,\n",
    "    'scaler': scaler,\n",
    "    'r2_score': r2,\n",
    "    'rmse': rmse,\n",
    "    'coeficiente': modelo.coef_[0],\n",
    "    'intercepto': modelo.intercept_,\n",
    "    'feature_names': ['Tamaño_m2']\n",
    "}\n",
    "\n",
    "with open('modelo_completo_casas.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo_completo, f)\n",
    "print(\"   ✓ Modelo completo guardado: modelo_completo_casas.pkl\")\n",
    "print(\"\\n\" + \"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d643b474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. GUARDANDO MODELO CON JOBLIB (RECOMENDADO):\n",
      "   ------------------------------------------------------------------\n",
      "   ✓ Modelo guardado: modelo_casas.joblib\n",
      "   ✓ Escalador guardado: scaler_casas.joblib\n",
      "   ✓ Modelo completo guardado: modelo_completo_casas.joblib\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. GUARDAR CON JOBLIB (método recomendado para scikit-learn - más rápido)\n",
    "print(\"4. GUARDANDO MODELO CON JOBLIB (RECOMENDADO):\")\n",
    "print(\"   \" + \"-\" * 66)\n",
    "\n",
    "# Joblib es más eficiente que Pickle para modelos con arrays grandes de NumPy\n",
    "joblib.dump(modelo, 'modelo_casas.joblib')\n",
    "print(\"   ✓ Modelo guardado: modelo_casas.joblib\")\n",
    "\n",
    "joblib.dump(scaler, 'scaler_casas.joblib')\n",
    "print(\"   ✓ Escalador guardado: scaler_casas.joblib\")\n",
    "\n",
    "# Guardar todo junto con joblib\n",
    "joblib.dump(modelo_completo, 'modelo_completo_casas.joblib')\n",
    "print(\"   ✓ Modelo completo guardado: modelo_completo_casas.joblib\")\n",
    "print(\"\\n\" + \"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cd6e20f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. CARGANDO MODELO DESDE ARCHIVO PKL:\n",
      "   ------------------------------------------------------------------\n",
      "   ✓ Modelo cargado desde: modelo_casas.pkl\n",
      "   ✓ Escalador cargado desde: scaler_casas.pkl\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. CARGAR Y USAR MODELO GUARDADO (Simulando nueva sesión)\n",
    "print(\"5. CARGANDO MODELO DESDE ARCHIVO PKL:\")\n",
    "print(\"   \" + \"-\" * 66)\n",
    "\n",
    "# Simular que estamos en una nueva sesión (no tenemos el modelo en memoria)\n",
    "# Borrar variables para simular nueva sesión\n",
    "del modelo, scaler, modelo_completo\n",
    "\n",
    "# Cargar modelo con Pickle\n",
    "with open('modelo_casas.pkl', 'rb') as f:  # 'rb' = read binary (leer binario)\n",
    "    modelo_cargado = pickle.load(f)\n",
    "\n",
    "with open('scaler_casas.pkl', 'rb') as f:\n",
    "    scaler_cargado = pickle.load(f)\n",
    "\n",
    "print(\"   ✓ Modelo cargado desde: modelo_casas.pkl\")\n",
    "print(\"   ✓ Escalador cargado desde: scaler_casas.pkl\")\n",
    "print(\"\\n\" + \"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bf812ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. HACIENDO PREDICCIONES CON EL MODELO CARGADO:\n",
      "   ------------------------------------------------------------------\n",
      "   Para una casa de 100 m²:\n",
      "   Precio predicho: $145,024.06\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. HACER PREDICCIONES CON EL MODELO CARGADO\n",
    "print(\"6. HACIENDO PREDICCIONES CON EL MODELO CARGADO:\")\n",
    "print(\"   \" + \"-\" * 66)\n",
    "\n",
    "# Nueva casa para predecir\n",
    "nueva_casa = pd.DataFrame({'Tamaño_m2': [100]})  # Casa de 100 m²\n",
    "\n",
    "# IMPORTANTE: Aplicar el mismo preprocesamiento que en el entrenamiento\n",
    "# 1. Escalar los datos nuevos con el escalador guardado\n",
    "nueva_casa_scaled = scaler_cargado.transform(nueva_casa)\n",
    "\n",
    "# 2. Hacer predicción\n",
    "precio_predicho = modelo_cargado.predict(nueva_casa_scaled)\n",
    "\n",
    "print(f\"   Para una casa de {nueva_casa['Tamaño_m2'][0]} m²:\")\n",
    "print(f\"   Precio predicho: ${precio_predicho[0]:,.2f}\")\n",
    "print(\"\\n\" + \"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d66931b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. CARGANDO MODELO COMPLETO:\n",
      "   ------------------------------------------------------------------\n",
      "   Información del modelo cargado:\n",
      "   - R² Score: 0.8852\n",
      "   - RMSE: 14868.47\n",
      "   - Coeficiente: 65218.56\n",
      "   - Intercepto: 206379.86\n",
      "   - Features: ['Tamaño_m2']\n",
      "\n",
      "   Predicción con modelo del diccionario: $145,024.06\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 7. CARGAR MODELO COMPLETO (con toda la información)\n",
    "print(\"7. CARGANDO MODELO COMPLETO:\")\n",
    "print(\"   \" + \"-\" * 66)\n",
    "\n",
    "with open('modelo_completo_casas.pkl', 'rb') as f:\n",
    "    modelo_completo_cargado = pickle.load(f)\n",
    "\n",
    "print(\"   Información del modelo cargado:\")\n",
    "print(f\"   - R² Score: {modelo_completo_cargado['r2_score']:.4f}\")\n",
    "print(f\"   - RMSE: {modelo_completo_cargado['rmse']:.2f}\")\n",
    "print(f\"   - Coeficiente: {modelo_completo_cargado['coeficiente']:.2f}\")\n",
    "print(f\"   - Intercepto: {modelo_completo_cargado['intercepto']:.2f}\")\n",
    "print(f\"   - Features: {modelo_completo_cargado['feature_names']}\")\n",
    "\n",
    "# Usar el modelo del diccionario\n",
    "modelo_del_diccionario = modelo_completo_cargado['modelo']\n",
    "scaler_del_diccionario = modelo_completo_cargado['scaler']\n",
    "\n",
    "# Hacer predicción\n",
    "nueva_casa_scaled = scaler_del_diccionario.transform(nueva_casa)\n",
    "precio_predicho = modelo_del_diccionario.predict(nueva_casa_scaled)\n",
    "print(f\"\\n   Predicción con modelo del diccionario: ${precio_predicho[0]:,.2f}\")\n",
    "print(\"\\n\" + \"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "35420391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. CARGANDO MODELO CON JOBLIB:\n",
      "   ------------------------------------------------------------------\n",
      "   ✓ Modelo cargado con Joblib\n",
      "   ✓ Escalador cargado con Joblib\n",
      "   Predicción: $145,024.06\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 8. CARGAR CON JOBLIB (método más rápido)\n",
    "print(\"8. CARGANDO MODELO CON JOBLIB:\")\n",
    "print(\"   \" + \"-\" * 66)\n",
    "\n",
    "# Joblib es más rápido que Pickle para cargar\n",
    "modelo_joblib = joblib.load('modelo_casas.joblib')\n",
    "scaler_joblib = joblib.load('scaler_casas.joblib')\n",
    "\n",
    "print(\"   ✓ Modelo cargado con Joblib\")\n",
    "print(\"   ✓ Escalador cargado con Joblib\")\n",
    "\n",
    "# Predicción\n",
    "nueva_casa_scaled = scaler_joblib.transform(nueva_casa)\n",
    "precio_predicho = modelo_joblib.predict(nueva_casa_scaled)\n",
    "print(f\"   Predicción: ${precio_predicho[0]:,.2f}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f33b8",
   "metadata": {},
   "source": [
    "### **5.6 Resumen: Flujo completo de guardado y carga**\n",
    "\n",
    "```\n",
    "ENTRENAMIENTO:\n",
    "1. Entrenar modelo → modelo.fit(X_train, y_train)\n",
    "2. Guardar modelo → pickle.dump(modelo, archivo) o joblib.dump()\n",
    "3. Guardar escalador → pickle.dump(scaler, archivo)\n",
    "\n",
    "DEPLOYMENT (Despliegue):\n",
    "1. Cargar modelo → modelo = pickle.load(archivo)\n",
    "2. Cargar escalador → scaler = pickle.load(archivo)\n",
    "3. Preprocesar datos nuevos → datos_scaled = scaler.transform(datos_nuevos)\n",
    "4. Predecir → predicciones = modelo.predict(datos_scaled)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a2c60",
   "metadata": {},
   "source": [
    "### **5.7 Ejemplo de despliegue en producción**\n",
    "\n",
    "A continuación se presenta un ejemplo de cómo crear una función de predicción lista para producción:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "81b06f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EJEMPLO: FUNCIÓN DE PREDICCIÓN PARA PRODUCCIÓN\n",
      "======================================================================\n",
      "\n",
      "Predicciones de precios para diferentes tamaños:\n",
      "----------------------------------------------------------------------\n",
      "  Casa de  80 m² → Precio: $114,617.64\n",
      "  Casa de 100 m² → Precio: $145,024.06\n",
      "  Casa de 120 m² → Precio: $175,430.47\n",
      "  Casa de 150 m² → Precio: $221,040.09\n",
      "  Casa de 180 m² → Precio: $266,649.71\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EJEMPLO: FUNCIÓN DE PREDICCIÓN PARA PRODUCCIÓN\n",
    "# ============================================\n",
    "\n",
    "def predecir_precio_casa(tamaño_m2, ruta_modelo='modelo_completo_casas.pkl'):\n",
    "    \"\"\"\n",
    "    Función para predecir el precio de una casa basándose en su tamaño.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    tamaño_m2 : float o int\n",
    "        Tamaño de la casa en metros cuadrados\n",
    "    ruta_modelo : str\n",
    "        Ruta al archivo del modelo guardado (por defecto 'modelo_completo_casas.pkl')\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    dict : Diccionario con la predicción y metadatos\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Cargar modelo completo\n",
    "        with open(ruta_modelo, 'rb') as f:\n",
    "            modelo_completo = pickle.load(f)\n",
    "        \n",
    "        # Extraer componentes\n",
    "        modelo = modelo_completo['modelo']\n",
    "        scaler = modelo_completo['scaler']\n",
    "        \n",
    "        # Preparar datos\n",
    "        datos_nuevos = pd.DataFrame({'Tamaño_m2': [tamaño_m2]})\n",
    "        \n",
    "        # Aplicar preprocesamiento (ESCALADO)\n",
    "        datos_scaled = scaler.transform(datos_nuevos)\n",
    "        \n",
    "        # Predecir\n",
    "        precio_predicho = modelo.predict(datos_scaled)[0]\n",
    "        \n",
    "        # Retornar resultado\n",
    "        resultado = {\n",
    "            'tamaño_m2': tamaño_m2,\n",
    "            'precio_predicho': round(precio_predicho, 2),\n",
    "            'modelo_usado': 'Linear Regression',\n",
    "            'r2_score': modelo_completo['r2_score'],\n",
    "            'rmse': modelo_completo['rmse'],\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        return resultado\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'mensaje': f'No se encontró el archivo del modelo: {ruta_modelo}'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'mensaje': f'Error al hacer predicción: {str(e)}'\n",
    "        }\n",
    "\n",
    "\n",
    "# Probar la función de predicción\n",
    "print(\"=\" * 70)\n",
    "print(\"EJEMPLO: FUNCIÓN DE PREDICCIÓN PARA PRODUCCIÓN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Hacer varias predicciones\n",
    "casas_ejemplo = [80, 100, 120, 150, 180]\n",
    "\n",
    "print(\"\\nPredicciones de precios para diferentes tamaños:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for tamaño in casas_ejemplo:\n",
    "    resultado = predecir_precio_casa(tamaño)\n",
    "    if resultado['status'] == 'success':\n",
    "        print(f\"  Casa de {resultado['tamaño_m2']:3d} m² → Precio: ${resultado['precio_predicho']:>10,.2f}\")\n",
    "    else:\n",
    "        print(f\"  Error: {resultado['mensaje']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d1d948",
   "metadata": {},
   "source": [
    "### **5.8 Casos de uso comunes para modelos PKL**\n",
    "\n",
    "1. **Sistemas de producción**: Desplegar modelos en servidores web o APIs\n",
    "2. **Aplicaciones web**: Usar modelos en Flask, FastAPI o Django\n",
    "3. **Scripts automatizados**: Ejecutar predicciones en lotes (batch)\n",
    "4. **Análisis ad-hoc**: Cargar modelos pre-entrenados para análisis rápidos\n",
    "5. **Compartir modelos**: Enviar modelos entrenados a colegas o clientes\n",
    "6. **Versionado**: Mantener diferentes versiones de modelos (v1.pkl, v2.pkl, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5e5da",
   "metadata": {},
   "source": [
    "### **5.9 Mejores prácticas**\n",
    "\n",
    "1. **Siempre guarda el escalador**: Los datos nuevos deben escalarse igual que los de entrenamiento\n",
    "2. **Documenta los metadatos**: Guarda información sobre el modelo (fecha, métricas, versión)\n",
    "3. **Usa Joblib para scikit-learn**: Es más rápido que Pickle para arrays grandes\n",
    "4. **Valida antes de desplegar**: Prueba el modelo cargado con datos conocidos\n",
    "5. **Versiona tus modelos**: Usa nombres descriptivos (modelo_v1.pkl, modelo_20241114.pkl)\n",
    "6. **Maneja errores**: Incluye try-except al cargar modelos\n",
    "7. **Verifica compatibilidad**: Asegúrate de usar las mismas versiones de librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cc53fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFICACIÓN DEL MODELO CARGADO\n",
      "======================================================================\n",
      "✓ Modelo cargado exitosamente desde: modelo_completo_casas.pkl\n",
      "  - Tipo de modelo: LinearRegression\n",
      "  - R² Score guardado: 0.8852\n",
      "  - RMSE guardado: 14868.47\n",
      "\n",
      "✓ Predicciones generadas correctamente: 6 predicciones\n",
      "  Rango de predicciones: $99,414.44 - $224,080.73\n",
      "\n",
      "✓ Modelo verificado y listo para usar\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# EJEMPLO: VERIFICAR MODELO CARGADO\n",
    "# ============================================\n",
    "\n",
    "def verificar_modelo_cargado(ruta_modelo='modelo_completo_casas.pkl', datos_prueba=None):\n",
    "    \"\"\"\n",
    "    Verifica que un modelo cargado funcione correctamente\n",
    "    comparando predicciones con datos de prueba conocidos.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Cargar modelo\n",
    "        with open(ruta_modelo, 'rb') as f:\n",
    "            modelo_completo = pickle.load(f)\n",
    "        \n",
    "        modelo = modelo_completo['modelo']\n",
    "        scaler = modelo_completo['scaler']\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"VERIFICACIÓN DEL MODELO CARGADO\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"✓ Modelo cargado exitosamente desde: {ruta_modelo}\")\n",
    "        print(f\"  - Tipo de modelo: {type(modelo).__name__}\")\n",
    "        print(f\"  - R² Score guardado: {modelo_completo['r2_score']:.4f}\")\n",
    "        print(f\"  - RMSE guardado: {modelo_completo['rmse']:.2f}\")\n",
    "        \n",
    "        # Probar con datos de prueba si están disponibles\n",
    "        if datos_prueba is not None:\n",
    "            X_test_scaled = scaler.transform(datos_prueba[['Tamaño_m2']])\n",
    "            predicciones = modelo.predict(X_test_scaled)\n",
    "            print(f\"\\n✓ Predicciones generadas correctamente: {len(predicciones)} predicciones\")\n",
    "            print(f\"  Rango de predicciones: ${predicciones.min():,.2f} - ${predicciones.max():,.2f}\")\n",
    "        \n",
    "        print(\"\\n✓ Modelo verificado y listo para usar\")\n",
    "        print(\"=\" * 70)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error al verificar modelo: {str(e)}\")\n",
    "        print(\"=\" * 70)\n",
    "        return False\n",
    "\n",
    "\n",
    "# Verificar modelo cargado\n",
    "verificar_modelo_cargado('modelo_completo_casas.pkl', X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d9ead",
   "metadata": {},
   "source": [
    "### **5.10 Resumen final: Pickle vs Joblib**\n",
    "\n",
    "| Característica | Pickle | Joblib |\n",
    "|----------------|--------|--------|\n",
    "| **Uso** | Estándar de Python | Específico para NumPy/scikit-learn |\n",
    "| **Velocidad** | Más lento | Más rápido para arrays grandes |\n",
    "| **Tamaño archivo** | Más grande | Más pequeño para arrays NumPy |\n",
    "| **Compatibilidad** | Universal en Python | Requiere joblib instalado |\n",
    "| **Recomendado para** | Objetos generales | Modelos de scikit-learn |\n",
    "\n",
    "**Conclusión**: Para modelos de scikit-learn, **Joblib es la mejor opción**. Para otros objetos de Python, usa Pickle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d38d4",
   "metadata": {},
   "source": [
    "## **6. Principales comandos de PyTorch**\n",
    "\n",
    "PyTorch es una librería de Python para redes neuronales y deep learning. Es un framework de machine learning basado en tensores y redes neuronales, desarrollado por Facebook AI Research. Es especialmente útil para deep learning y modelos avanzados de machine learning.\n",
    "\n",
    "### **Instalación**\n",
    "```python\n",
    "pip install torch torchvision\n",
    "```\n",
    "\n",
    "### **Importaciones básicas**\n",
    "- `import torch` - Importar PyTorch principal\n",
    "- `import torch.nn as nn` - Módulo de redes neuronales\n",
    "- `import torch.optim as optim` - Optimizadores (SGD, Adam, etc.)\n",
    "- `from torch.utils.data import Dataset, DataLoader` - Para manejo de datos\n",
    "\n",
    "### **Creación y manipulación de tensores**\n",
    "- `torch.tensor()` - Crear un tensor desde datos\n",
    "- `torch.zeros()` - Crear tensor de ceros\n",
    "- `torch.ones()` - Crear tensor de unos\n",
    "- `torch.randn()` - Crear tensor con valores aleatorios (distribución normal)\n",
    "- `torch.arange()` - Crear tensor con rango de valores\n",
    "- `tensor.shape` - Obtener dimensiones del tensor\n",
    "- `tensor.dtype` - Obtener tipo de datos del tensor\n",
    "- `tensor.requires_grad` - Habilitar cálculo de gradientes\n",
    "\n",
    "### **Operaciones con tensores**\n",
    "- `tensor1 + tensor2` - Suma elemento a elemento\n",
    "- `tensor1 * tensor2` - Multiplicación elemento a elemento\n",
    "- `torch.matmul()` - Multiplicación de matrices\n",
    "- `tensor.sum()` - Suma de todos los elementos\n",
    "- `tensor.mean()` - Media de todos los elementos\n",
    "- `tensor.item()` - Obtener valor escalar de tensor de 1 elemento\n",
    "- `tensor.numpy()` - Convertir tensor a array de NumPy\n",
    "- `torch.from_numpy()` - Convertir array de NumPy a tensor\n",
    "\n",
    "### **Dispositivos (CPU/GPU)**\n",
    "- `torch.device('cpu')` - Dispositivo CPU\n",
    "- `torch.device('cuda')` - Dispositivo GPU (si está disponible)\n",
    "- `torch.cuda.is_available()` - Verificar si GPU está disponible\n",
    "- `tensor.to(device)` - Mover tensor a dispositivo (CPU o GPU)\n",
    "- `model.to(device)` - Mover modelo a dispositivo\n",
    "\n",
    "### **Redes neuronales (nn.Module)**\n",
    "- `nn.Linear(in_features, out_features)` - Capa completamente conectada\n",
    "- `nn.ReLU()` - Función de activación ReLU\n",
    "- `nn.Sigmoid()` - Función de activación Sigmoid\n",
    "- `nn.Tanh()` - Función de activación Tanh\n",
    "- `nn.Dropout(p)` - Capa de dropout para regularización\n",
    "- `nn.Sequential()` - Contenedor para apilar capas secuencialmente\n",
    "\n",
    "### **Pérdidas (Loss Functions)**\n",
    "- `nn.MSELoss()` - Error cuadrático medio (para regresión)\n",
    "- `nn.CrossEntropyLoss()` - Pérdida de entropía cruzada (para clasificación)\n",
    "- `nn.L1Loss()` - Error absoluto medio (para regresión)\n",
    "- `nn.BCELoss()` - Pérdida de entropía cruzada binaria\n",
    "\n",
    "### **Optimizadores**\n",
    "- `optim.SGD(model.parameters(), lr=0.01)` - Descenso de gradiente estocástico\n",
    "- `optim.Adam(model.parameters(), lr=0.001)` - Optimizador Adam (recomendado)\n",
    "- `optim.AdamW()` - Adam con decaimiento de peso\n",
    "- `optim.RMSprop()` - RMSprop optimizador\n",
    "- `optimizer.zero_grad()` - Limpiar gradientes acumulados\n",
    "- `optimizer.step()` - Actualizar parámetros del modelo\n",
    "\n",
    "### **Entrenamiento básico**\n",
    "- `loss.backward()` - Calcular gradientes (backpropagation)\n",
    "- `model.train()` - Modo entrenamiento (habilita dropout, etc.)\n",
    "- `model.eval()` - Modo evaluación (deshabilita dropout, etc.)\n",
    "- `torch.no_grad()` - Deshabilitar cálculo de gradientes (para evaluación)\n",
    "\n",
    "### **Guardar y cargar modelos**\n",
    "- `torch.save(model.state_dict(), 'modelo.pth')` - Guardar pesos del modelo\n",
    "- `torch.load('modelo.pth')` - Cargar pesos del modelo\n",
    "- `model.load_state_dict()` - Cargar pesos en el modelo\n",
    "- `torch.save(model, 'modelo_completo.pth')` - Guardar modelo completo\n",
    "\n",
    "### **Dataset y DataLoader**\n",
    "- `Dataset` - Clase base para datasets personalizados\n",
    "- `DataLoader(dataset, batch_size, shuffle)` - Cargador de datos por lotes\n",
    "- `__len__()` - Método para obtener tamaño del dataset\n",
    "- `__getitem__()` - Método para obtener un elemento del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b689e",
   "metadata": {},
   "source": [
    "### **6.1 ¿Qué es PyTorch?**\n",
    "\n",
    "**PyTorch** es un framework de machine learning basado en tensores (arrays multidimensionales) que permite construir y entrenar redes neuronales de manera eficiente.\n",
    "\n",
    "### **Características principales:**\n",
    "\n",
    "1. **Tensores**: Estructuras de datos similares a arrays de NumPy pero optimizadas para cálculo numérico y deep learning\n",
    "2. **Diferenciación automática**: Calcula gradientes automáticamente (útil para backpropagation)\n",
    "3. **Redes neuronales**: Construcción modular de redes neuronales profundas\n",
    "4. **GPU support**: Acelera cálculos usando tarjetas gráficas (CUDA)\n",
    "5. **Pythonic**: API intuitiva y fácil de usar, similar a NumPy\n",
    "\n",
    "### **Conceptos clave:**\n",
    "\n",
    "- **Tensor**: Array multidimensional (similar a NumPy array pero con capacidades de GPU y diferenciación automática)\n",
    "- **Autograd**: Sistema de diferenciación automática que calcula gradientes\n",
    "- **nn.Module**: Clase base para definir redes neuronales\n",
    "- **Optimizer**: Algoritmo que actualiza los pesos de la red durante el entrenamiento\n",
    "- **Loss Function**: Función que mide qué tan lejos están las predicciones de los valores reales\n",
    "\n",
    "### **Cuándo usar PyTorch:**\n",
    "\n",
    "- **Redes neuronales profundas**: Para modelos complejos con muchas capas\n",
    "- **Deep learning avanzado**: CNN, RNN, Transformers, etc.\n",
    "- **Investigación**: Flexibilidad para experimentar con arquitecturas nuevas\n",
    "- **GPU**: Cuando necesitas aceleración de GPU para entrenar modelos grandes\n",
    "\n",
    "### **Ejemplo típico de uso:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Definir una red neuronal simple\n",
    "class RedSimple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.capa1 = nn.Linear(10, 64)  # 10 entradas, 64 salidas\n",
    "        self.capa2 = nn.Linear(64, 1)   # 64 entradas, 1 salida\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.capa1(x))\n",
    "        x = self.capa2(x)\n",
    "        return x\n",
    "\n",
    "# Crear modelo y entrenarlo\n",
    "modelo = RedSimple()\n",
    "```\n",
    "\n",
    "En el proyecto, PyTorch se puede usar para crear modelos de regresión más avanzados basados en redes neuronales que pueden capturar relaciones no lineales complejas en los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c9c3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "96de7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EJEMPLO: REGRESIÓN CON RED NEURONAL EN PYTORCH\n",
      "======================================================================\n",
      "\n",
      "1. Datos de ejemplo creados:\n",
      "   Tamaño_m2    Precio\n",
      "0      152.0  213311.0\n",
      "1      142.0  230819.0\n",
      "2       64.0  115188.0\n",
      "3      156.0  231568.0\n",
      "4      121.0  181269.0\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EJEMPLO SIMPLE CON PYTORCH\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EJEMPLO: REGRESIÓN CON RED NEURONAL EN PYTORCH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Crear datos de ejemplo (mismo ejemplo que scikit-learn para comparación)\n",
    "np.random.seed(42)\n",
    "tamaño = np.random.randint(50, 200, 20).astype(float)\n",
    "precio = (tamaño * 1500 + np.random.randint(-20000, 20000, 20)).astype(float)\n",
    "\n",
    "print(\"\\n1. Datos de ejemplo creados:\")\n",
    "df_casas = pd.DataFrame({\n",
    "    'Tamaño_m2': tamaño,\n",
    "    'Precio': precio\n",
    "})\n",
    "print(df_casas.head())\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1c251c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Datos convertidos a tensores de PyTorch:\n",
      "   X shape: torch.Size([20, 1])\n",
      "   y shape: torch.Size([20, 1])\n",
      "   Tipo de X: torch.float32\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. Convertir datos de NumPy a tensores de PyTorch\n",
    "X = torch.tensor(tamaño.reshape(-1, 1), dtype=torch.float32)  # Convertir a tensor 2D\n",
    "y = torch.tensor(precio.reshape(-1, 1), dtype=torch.float32)  # Convertir a tensor 2D\n",
    "\n",
    "print(\"2. Datos convertidos a tensores de PyTorch:\")\n",
    "print(f\"   X shape: {X.shape}\")  # (20, 1) - 20 muestras, 1 característica\n",
    "print(f\"   y shape: {y.shape}\")  # (20, 1) - 20 muestras, 1 salida\n",
    "print(f\"   Tipo de X: {X.dtype}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "49b82d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Red neuronal creada:\n",
      "   Modelo: RedRegresion(\n",
      "  (capa_oculta): Linear(in_features=1, out_features=64, bias=True)\n",
      "  (activacion): ReLU()\n",
      "  (capa_salida): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3. Definir una red neuronal simple para regresión\n",
    "class RedRegresion(nn.Module):\n",
    "    \"\"\"\n",
    "    Red neuronal simple para regresión:\n",
    "    - Una capa de entrada (1 característica)\n",
    "    - Una capa oculta (64 neuronas)\n",
    "    - Una capa de salida (1 valor)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(RedRegresion, self).__init__()\n",
    "        self.capa_oculta = nn.Linear(1, 64)  # 1 entrada -> 64 salidas\n",
    "        self.activacion = nn.ReLU()          # Función de activación\n",
    "        self.capa_salida = nn.Linear(64, 1)  # 64 entradas -> 1 salida\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pasar datos a través de la red\n",
    "        x = self.capa_oculta(x)    # Capa oculta\n",
    "        x = self.activacion(x)     # Activación ReLU\n",
    "        x = self.capa_salida(x)    # Capa de salida\n",
    "        return x\n",
    "\n",
    "# Crear instancia del modelo\n",
    "modelo = RedRegresion()\n",
    "print(\"3. Red neuronal creada:\")\n",
    "print(f\"   Modelo: {modelo}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d9313e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Configuración de entrenamiento:\n",
      "   Función de pérdida: MSELoss()\n",
      "   Optimizador: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. Definir función de pérdida y optimizador\n",
    "criterio = nn.MSELoss()  # Error cuadrático medio (para regresión)\n",
    "optimizador = optim.Adam(modelo.parameters(), lr=0.001)  # Optimizador Adam\n",
    "\n",
    "print(\"4. Configuración de entrenamiento:\")\n",
    "print(f\"   Función de pérdida: {criterio}\")\n",
    "print(f\"   Optimizador: {optimizador}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "51dcc8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Entrenando modelo...\n",
      "   Época 200/1000, Pérdida: 43270742016.00\n",
      "   Época 400/1000, Pérdida: 42693136384.00\n",
      "   Época 600/1000, Pérdida: 41803726848.00\n",
      "   Época 800/1000, Pérdida: 40636276736.00\n",
      "   Época 1000/1000, Pérdida: 39226368000.00\n",
      "\n",
      "   ✓ Entrenamiento completado\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. Entrenar el modelo\n",
    "num_epochs = 1000  # Número de iteraciones de entrenamiento\n",
    "modelo.train()  # Poner modelo en modo entrenamiento\n",
    "\n",
    "print(\"5. Entrenando modelo...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Limpiar gradientes anteriores\n",
    "    optimizador.zero_grad()\n",
    "    \n",
    "    # Forward pass: calcular predicciones\n",
    "    predicciones = modelo(X)\n",
    "    \n",
    "    # Calcular pérdida\n",
    "    perdida = criterio(predicciones, y)\n",
    "    \n",
    "    # Backward pass: calcular gradientes\n",
    "    perdida.backward()\n",
    "    \n",
    "    # Actualizar pesos\n",
    "    optimizador.step()\n",
    "    \n",
    "    # Mostrar progreso cada 200 épocas\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"   Época {epoch + 1}/{num_epochs}, Pérdida: {perdida.item():.2f}\")\n",
    "\n",
    "print(\"\\n   ✓ Entrenamiento completado\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "346de6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Predicciones del modelo:\n",
      "   Tamaño_m2  Precio_Real  Precio_Predicho\n",
      "0      152.0     213311.0     11626.219727\n",
      "1      142.0     230819.0     10864.930664\n",
      "2       64.0     115188.0      4926.882324\n",
      "3      156.0     231568.0     11930.734375\n",
      "4      121.0     181269.0      9266.225586\n",
      "5       70.0     113693.0      5383.654785\n",
      "6      152.0     214396.0     11626.219727\n",
      "7      171.0     263980.0     13072.666992\n",
      "8      124.0     191658.0      9494.612305\n",
      "9      137.0     204442.0     10484.286133\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. Hacer predicciones\n",
    "modelo.eval()  # Poner modelo en modo evaluación\n",
    "\n",
    "# Hacer predicciones (sin calcular gradientes)\n",
    "with torch.no_grad():\n",
    "    predicciones = modelo(X)\n",
    "\n",
    "# Convertir a NumPy para visualización\n",
    "predicciones_np = predicciones.numpy()\n",
    "precio_real_np = y.numpy()\n",
    "\n",
    "print(\"6. Predicciones del modelo:\")\n",
    "resultados = pd.DataFrame({\n",
    "    'Tamaño_m2': tamaño,\n",
    "    'Precio_Real': precio_real_np.flatten(),\n",
    "    'Precio_Predicho': predicciones_np.flatten()\n",
    "})\n",
    "print(resultados.head(10))\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6ca1fb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. Métricas de evaluación del modelo:\n",
      "   R² Score: -9.4181\n",
      "   MSE: 39218782208.00\n",
      "   RMSE: 198037.33\n",
      "   MAE: 189235.88\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluar el modelo con métricas\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "r2 = r2_score(precio_real_np, predicciones_np)\n",
    "mse = mean_squared_error(precio_real_np, predicciones_np)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(precio_real_np, predicciones_np)\n",
    "\n",
    "print(\"7. Métricas de evaluación del modelo:\")\n",
    "print(f\"   R² Score: {r2:.4f}\")\n",
    "print(f\"   MSE: {mse:.2f}\")\n",
    "print(f\"   RMSE: {rmse:.2f}\")\n",
    "print(f\"   MAE: {mae:.2f}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6ea984c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. Predicción para casa nueva:\n",
      "   Tamaño: 100 m²\n",
      "   Precio predicho: $7,667.52\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 8. Hacer predicción para una nueva casa\n",
    "nueva_casa = torch.tensor([[100.0]], dtype=torch.float32)  # Casa de 100 m²\n",
    "\n",
    "modelo.eval()\n",
    "with torch.no_grad():\n",
    "    precio_predicho = modelo(nueva_casa)\n",
    "\n",
    "print(f\"8. Predicción para casa nueva:\")\n",
    "print(f\"   Tamaño: {nueva_casa.item():.0f} m²\")\n",
    "print(f\"   Precio predicho: ${precio_predicho.item():,.2f}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e078a39",
   "metadata": {},
   "source": [
    "### **6.3 Comparación: PyTorch vs scikit-learn**\n",
    "\n",
    "| Característica | scikit-learn | PyTorch |\n",
    "|----------------|--------------|---------|\n",
    "| **Uso principal** | Machine Learning tradicional | Deep Learning |\n",
    "| **Facilidad** | Muy fácil de usar | Requiere más código |\n",
    "| **Modelos** | Algoritmos clásicos (RF, GBM, etc.) | Redes neuronales personalizadas |\n",
    "| **GPU** | No | Sí (muy rápido) |\n",
    "| **Gradientes** | No necesita | Calcula automáticamente |\n",
    "| **Casos de uso** | Datos tabulares, modelos simples | Datos complejos, imágenes, texto |\n",
    "| **Recomendado para** | Proyectos rápidos, prototipado | Modelos avanzados, investigación |\n",
    "\n",
    "**Conclusión**: Para la mayoría de problemas de regresión con datos tabulares, **scikit-learn es más simple y suficiente**. Usa **PyTorch** cuando necesites redes neuronales profundas, GPU, o modelos muy personalizados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6fa842",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053dc2fb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
